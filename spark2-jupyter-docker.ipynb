{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker Spark setup\n",
    "\n",
    "This notebook is meant to run on a spark 2 docker container. First i'll describe the steps to set it up.\n",
    "\n",
    "On a Linux based system install Docker and Docker-compose.Create this file : docker-compose.yml. The contents is listed below.  Then run: docker-compose build . Afterwards run this command : docker-compose build -d\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "version: \"2\"\n",
    "\n",
    "services:\n",
    "  master:\n",
    "    image: singularities/spark\n",
    "    command: start-spark master\n",
    "    hostname: master\n",
    "    ports:\n",
    "      - \"6066:6066\"\n",
    "      - \"7070:7070\"\n",
    "      - \"8080:8080\"\n",
    "      - \"50070:50070\"\n",
    "      - \"8888:8888\"\n",
    "  worker:\n",
    "    image: singularities/spark\n",
    "    command: start-spark worker master\n",
    "    environment:\n",
    "      SPARK_WORKER_CORES: 1\n",
    "      SPARK_WORKER_MEMORY: 2g\n",
    "    links:\n",
    "      - master\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "With docker ps , check if the master and worker containers are running.\n",
    "Connect to the master node:\n",
    "docker exec -it [container id master] bash\n",
    "On the master node continue with setting up as described below.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark and conda env setup\n",
    "\n",
    "```\n",
    "First install Anaconda 4 (latest version) on the Docker container with Spark Master. Then install a new Conda environment for Spark, using python 3.5 (3.6 has a bug).  \n",
    "\n",
    "conda create -n spark python=3.5\n",
    "source activate spark\n",
    "conda install notebook ipykernel\n",
    "ipython kernel install --user --name spark --display-name spark\n",
    "\n",
    "Make jupyter start script, and run it:\n",
    "PYSPARK_PYTHON=/root/anaconda3/envs/spark/bin/python\n",
    "PYSPARK_DRIVER_PYTHON=jupyter PYSPARK_DRIVER_PYTHON_OPTS='notebook --ip=0.0.0.0 --port=8888' $SPARK_HOME/bin/pyspark\n",
    "\n",
    "Now go to the url it gives (http://0.0.0.0:8888/<some code>)\n",
    ", Run the nodebook sections.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Start this in spark conda env to test\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "import pyspark.sql.functions as fn\n",
    "import pyspark.sql.types as typ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example data\n",
    "\n",
    "```\n",
    "This example works if you clone https://github.com/PacktPublishing/Learning-PySpark\n",
    "\n",
    "and make sure its in /root/learningPySpark on the Docker container with Spark Master. \n",
    "\n",
    "To install git on this container run command: apt-get install git\n",
    ", on github (or bitbucket) create a repository so you can save changes from the container and push it to Github. Use the following commands on the Docker container to init and push the data :\n",
    "\n",
    "git init\n",
    "git add <your file>\n",
    "git commit -m \"first commit\"\n",
    "git remote add origin https://github.com/michelnossin/pyspark_training_docker.git\n",
    "git push -u origin master\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[date: string, delay: string, distance: string, origin: string, destination: string]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RANDOM FLIGHTS SET, AND WORLD AIRPORT SET\n",
    "flights = \"file:/root/learningPySpark/Chapter03/flight-data/departuredelays.csv\" \n",
    "airports = \"file:/root/learningPySpark/Chapter03/flight-data/airport-codes-na.txt\" \n",
    "airports_df = spark.read.csv(airports,header='true',inferSchema='true',sep='\\t')\n",
    "airports_df.createOrReplaceTempView(\"airports\")\n",
    "flights_df = spark.read.csv(flights,header='true')\n",
    "flights_df.createOrReplaceTempView(\"flights\")\n",
    "flights_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[na: string, altitude: string, dest: string, heading: string, flight: string, na2: string, landed: string, time: string, lat: string, lon: string, na3: string, org: string, na4: string, registration: string, flight2: string, na5: string, na6: string, planetype: string, na7: string]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RADAR TRACK\n",
    "track_file = \"file:/root/fr24/fr24_20160624.csv\"\n",
    "header=['na','altitude','dest','heading','flight','na2','landed','time','lat',\\\n",
    "         'lon','na3','org','na4','registration','flight2','na5','na6','planetype', 'na7']\n",
    "fields = [ *[\n",
    "           typ.StructField(h, typ.StringType(), True)\n",
    "           for h in header\n",
    "       ]\n",
    "   ]\n",
    "schema = typ.StructType(fields)\n",
    "schema   \n",
    "tracks_df = spark.read.csv(track_file,header='false',schema=schema)\n",
    "\n",
    "#filter tracks early to make it speed up\n",
    "tracks_df = tracks_df.where(\"dest == 'AMS'\") #14 milj -> 114k\n",
    "tracks_df.createOrReplaceTempView(\"tracks\")\n",
    "tracks_df.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First look at data:\n",
    "\n",
    "```\n",
    "source activate spark\n",
    "python -m pip install pandas\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "| 1391578|\n",
      "+--------+\n",
      "\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|     526|\n",
      "+--------+\n",
      "\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  114728|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count(1) from flights\").show()\n",
    "spark.sql(\"select count(1) from airports\").show()\n",
    "spark.sql(\"select count(1) from tracks\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>delay</th>\n",
       "      <th>distance</th>\n",
       "      <th>origin</th>\n",
       "      <th>destination</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01011245</td>\n",
       "      <td>6</td>\n",
       "      <td>602</td>\n",
       "      <td>ABE</td>\n",
       "      <td>ATL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01020600</td>\n",
       "      <td>-8</td>\n",
       "      <td>369</td>\n",
       "      <td>ABE</td>\n",
       "      <td>DTW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01021245</td>\n",
       "      <td>-2</td>\n",
       "      <td>602</td>\n",
       "      <td>ABE</td>\n",
       "      <td>ATL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01020605</td>\n",
       "      <td>-4</td>\n",
       "      <td>602</td>\n",
       "      <td>ABE</td>\n",
       "      <td>ATL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01031245</td>\n",
       "      <td>-4</td>\n",
       "      <td>602</td>\n",
       "      <td>ABE</td>\n",
       "      <td>ATL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date delay distance origin destination\n",
       "0  01011245     6      602    ABE         ATL\n",
       "1  01020600    -8      369    ABE         DTW\n",
       "2  01021245    -2      602    ABE         ATL\n",
       "3  01020605    -4      602    ABE         ATL\n",
       "4  01031245    -4      602    ABE         ATL"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Country</th>\n",
       "      <th>IATA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>BC</td>\n",
       "      <td>Canada</td>\n",
       "      <td>YXX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aberdeen</td>\n",
       "      <td>SD</td>\n",
       "      <td>USA</td>\n",
       "      <td>ABR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX</td>\n",
       "      <td>USA</td>\n",
       "      <td>ABI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Akron</td>\n",
       "      <td>OH</td>\n",
       "      <td>USA</td>\n",
       "      <td>CAK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alamosa</td>\n",
       "      <td>CO</td>\n",
       "      <td>USA</td>\n",
       "      <td>ALS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         City State Country IATA\n",
       "0  Abbotsford    BC  Canada  YXX\n",
       "1    Aberdeen    SD     USA  ABR\n",
       "2     Abilene    TX     USA  ABI\n",
       "3       Akron    OH     USA  CAK\n",
       "4     Alamosa    CO     USA  ALS"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airports_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>na</th>\n",
       "      <th>altitude</th>\n",
       "      <th>dest</th>\n",
       "      <th>heading</th>\n",
       "      <th>flight</th>\n",
       "      <th>na2</th>\n",
       "      <th>landed</th>\n",
       "      <th>time</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>na3</th>\n",
       "      <th>org</th>\n",
       "      <th>na4</th>\n",
       "      <th>registration</th>\n",
       "      <th>flight2</th>\n",
       "      <th>na5</th>\n",
       "      <th>na6</th>\n",
       "      <th>planetype</th>\n",
       "      <th>na7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>34000</td>\n",
       "      <td>AMS</td>\n",
       "      <td>295</td>\n",
       "      <td>OR752</td>\n",
       "      <td>a1e9dc7</td>\n",
       "      <td>0</td>\n",
       "      <td>1466725114</td>\n",
       "      <td>51</td>\n",
       "      <td>10</td>\n",
       "      <td>484AD0</td>\n",
       "      <td>BJV</td>\n",
       "      <td>F-ETHF1</td>\n",
       "      <td>PH-TFB</td>\n",
       "      <td>TFL752</td>\n",
       "      <td>442</td>\n",
       "      <td>3201</td>\n",
       "      <td>B738</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AMS</td>\n",
       "      <td>214</td>\n",
       "      <td>KL676</td>\n",
       "      <td>a1ee8d1</td>\n",
       "      <td>1</td>\n",
       "      <td>1466725291</td>\n",
       "      <td>53</td>\n",
       "      <td>-114</td>\n",
       "      <td>484FAD</td>\n",
       "      <td>YEG</td>\n",
       "      <td>F-CYEG1</td>\n",
       "      <td>PH-AON</td>\n",
       "      <td>KLM676</td>\n",
       "      <td>0</td>\n",
       "      <td>0000</td>\n",
       "      <td>A332</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3875</td>\n",
       "      <td>AMS</td>\n",
       "      <td>133</td>\n",
       "      <td>HV6332</td>\n",
       "      <td>a1eb5b5</td>\n",
       "      <td>0</td>\n",
       "      <td>1466725364</td>\n",
       "      <td>53</td>\n",
       "      <td>5</td>\n",
       "      <td>484F6C</td>\n",
       "      <td>VLC</td>\n",
       "      <td>T-EHAM31</td>\n",
       "      <td>PH-HSF</td>\n",
       "      <td>TRA48L</td>\n",
       "      <td>219</td>\n",
       "      <td>5576</td>\n",
       "      <td>B738</td>\n",
       "      <td>-1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>33000</td>\n",
       "      <td>AMS</td>\n",
       "      <td>15</td>\n",
       "      <td>KL702</td>\n",
       "      <td>a1e5d07</td>\n",
       "      <td>0</td>\n",
       "      <td>1466725993</td>\n",
       "      <td>-1</td>\n",
       "      <td>-40</td>\n",
       "      <td>4851B3</td>\n",
       "      <td>EZE</td>\n",
       "      <td>F-SBFZ3</td>\n",
       "      <td>PH-BVP</td>\n",
       "      <td>KLM702</td>\n",
       "      <td>490</td>\n",
       "      <td>0000</td>\n",
       "      <td>B77W</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AMS</td>\n",
       "      <td>5</td>\n",
       "      <td>KL604</td>\n",
       "      <td>a1eef34</td>\n",
       "      <td>1</td>\n",
       "      <td>1466726181</td>\n",
       "      <td>34</td>\n",
       "      <td>-118</td>\n",
       "      <td>48405E</td>\n",
       "      <td>LAX</td>\n",
       "      <td>F-KLAX1</td>\n",
       "      <td>PH-BFS</td>\n",
       "      <td>KL604</td>\n",
       "      <td>11</td>\n",
       "      <td>0000</td>\n",
       "      <td>B744</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  na  altitude dest  heading  flight      na2  landed        time  lat  lon  \\\n",
       "0  0     34000  AMS      295   OR752  a1e9dc7       0  1466725114   51   10   \n",
       "1  0         0  AMS      214   KL676  a1ee8d1       1  1466725291   53 -114   \n",
       "2  0      3875  AMS      133  HV6332  a1eb5b5       0  1466725364   53    5   \n",
       "3  0     33000  AMS       15   KL702  a1e5d07       0  1466725993   -1  -40   \n",
       "4  0         0  AMS        5   KL604  a1eef34       1  1466726181   34 -118   \n",
       "\n",
       "      na3  org       na4 registration flight2  na5   na6 planetype    na7  \n",
       "0  484AD0  BJV   F-ETHF1       PH-TFB  TFL752  442  3201      B738      0  \n",
       "1  484FAD  YEG   F-CYEG1       PH-AON  KLM676    0  0000      A332      0  \n",
       "2  484F6C  VLC  T-EHAM31       PH-HSF  TRA48L  219  5576      B738  -1024  \n",
       "3  4851B3  EZE   F-SBFZ3       PH-BVP  KLM702  490  0000      B77W      0  \n",
       "4  48405E  LAX   F-KLAX1       PH-BFS   KL604   11  0000      B744      0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- IATA: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airports_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: string (nullable = true)\n",
      " |-- delay: string (nullable = true)\n",
      " |-- distance: string (nullable = true)\n",
      " |-- origin: string (nullable = true)\n",
      " |-- destination: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights_df.printSchema() #date, delay and distance should change to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- na: string (nullable = true)\n",
      " |-- altitude: string (nullable = true)\n",
      " |-- dest: string (nullable = true)\n",
      " |-- heading: string (nullable = true)\n",
      " |-- flight: string (nullable = true)\n",
      " |-- na2: string (nullable = true)\n",
      " |-- landed: string (nullable = true)\n",
      " |-- time: string (nullable = true)\n",
      " |-- lat: string (nullable = true)\n",
      " |-- lon: string (nullable = true)\n",
      " |-- na3: string (nullable = true)\n",
      " |-- org: string (nullable = true)\n",
      " |-- na4: string (nullable = true)\n",
      " |-- registration: string (nullable = true)\n",
      " |-- flight2: string (nullable = true)\n",
      " |-- na5: string (nullable = true)\n",
      " |-- na6: string (nullable = true)\n",
      " |-- planetype: string (nullable = true)\n",
      " |-- na7: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tracks_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Change type of integer based columns , so we check outliers later on\n",
    "flights_df = flights_df.withColumn(\"delay\",flights_df[\"delay\"].cast(typ.IntegerType()))\n",
    "flights_df = flights_df.withColumn(\"distance\",flights_df[\"distance\"].cast(typ.IntegerType()))\n",
    "                   \n",
    "tracks_df = tracks_df.withColumn(\"altitude\",tracks_df[\"altitude\"].cast(typ.IntegerType()))      \n",
    "tracks_df = tracks_df.withColumn(\"heading\",tracks_df[\"heading\"].cast(typ.IntegerType()))   \n",
    "tracks_df = tracks_df.withColumn(\"lat\",tracks_df[\"lat\"].cast(typ.LongType()))  \n",
    "tracks_df = tracks_df.withColumn(\"lon\",tracks_df[\"lon\"].cast(typ.LongType())) \n",
    "tracks_df = tracks_df.withColumn(\"time\",tracks_df[\"time\"].cast(typ.LongType())) \n",
    "tracks_df = tracks_df.withColumn(\"landed\",tracks_df[\"landed\"].cast(typ.IntegerType()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Lets add a id columns for the flights\n",
    "flights_df = flights_df.withColumn('id',fn.monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data\n",
    "\n",
    "Your data can be stained with duplicates, missing observations and outliers, non- existent addresses, wrong phone numbers and area codes, inaccurate geographical coordinates, wrong dates, incorrect labels, mixtures of upper and lower cases, trailing spaces, and many other more subtle problems. It is your job to clean it, irrespective of whether you are a data scientist or data engineer,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicate rows check and remove\n",
    "First lets define some our spark util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def showDuplicateRowsCount(df):\n",
    "    'Show row count with full duplicated rows'\n",
    "    print(\"====Checking table duplicate rows =====\")\n",
    "    print('Count of rows: {0}'.format(df.count()))\n",
    "    print('Count of distinct rows: {0}'.format(df.distinct().count()))\n",
    "    print('===> nr of duplicate rows {0}'.format(df.count()-df.distinct().count()))\n",
    "def showDuplicatesColumnCount(df,col):\n",
    "    'Show duplicate rows based on a specific (id) col.'\n",
    "    print(\"=====Checking col {0}\".format(col))\n",
    "    print('Count of values: {0}'.format(df.count()))\n",
    "    distinct_col_count = df.select([\n",
    "           c for c in df.columns if c != col\n",
    "       ]).distinct().count()\n",
    "    print('Count of distinct column values: {0}'.format(distinct_col_count))\n",
    "    print (\"====> duplicate count {0}\".format(df.count() - distinct_col_count))\n",
    "def showDuplicatesColumnCountSpark(df,col):\n",
    "    'spark version of Showduplicatescolumncount()'\n",
    "    df.agg(\n",
    "       fn.count(col).alias('count'),\n",
    "       fn.countDistinct(col).alias('distinct')\n",
    "    ).show()\n",
    "def showDuplicateColumnsCount(df):\n",
    "    'Show duplicate rows based on all columns in a dataframe'\n",
    "    for col in df.columns:\n",
    "        showDuplicatesColumn(df,col)\n",
    "def dropDuplicateColumn(df,col):\n",
    "    'drop rows with duplicate columns based on certain (id) column'\n",
    "    df = df.dropDuplicates(subset=[\n",
    "       c for c in df.columns if c != col\n",
    "    ])\n",
    "#   \n",
    "#def getDFDuplicateColumns(df,col,new_col):\n",
    "#    uniq_df = df.select([\n",
    "#           c for c in df.columns if c != col\n",
    "#       ]).distinct()\n",
    "#    duplicate_df = df.subtract(uniq_df)\n",
    "#    \n",
    "#    return(duplicate_df.withColumn(new_col, \\\n",
    "#                            fn.monotonically_increasing_id()))\n",
    "#   **/ \n",
    "def showMissingDataPercent(df_miss):\n",
    "    'show each column and percentage of missing data, 0 - 1 , 0 means no missing data'\n",
    "    df_miss.agg(*[\n",
    "       (1 - (fn.count(c) / fn.count('*'))).alias(c + '_missing')\n",
    "       for c in df_miss.columns\n",
    "    ]).show()\n",
    "def getDFDropColumn(df_miss,col):\n",
    "    'Get a new dataframe based on another without given column'\n",
    "    return(df_miss.select([\n",
    "       c for c in df_miss.columns if c != col\n",
    "    ]))\n",
    "def getDFDropMissingRows(df_miss):\n",
    "    'Drop rows with any missing column field'\n",
    "    return(df_miss.dropna())\n",
    "def fillMissingMeanColumn(df,col):\n",
    "    'Fill in missing values in a certain column containing numerical data'\n",
    "    means = df.agg(\n",
    "       *[fn.mean(col).alias(col)\n",
    "           for c in df.columns if c != col]\n",
    "   ).toPandas().to_dict('records')[0]\n",
    "def getDFFillMissingCategoryColumn(df,col):\n",
    "    'Fill in missing values in a column containing a category and return df'\n",
    "    miss_dict = {col: \"missing\"}\n",
    "    return(df.fillna(miss_dict))\n",
    "def getDictOutliers(df_outliers,col_list):\n",
    "    'return dictionary with outliers boundaries , based on columns in list'\n",
    "    bounds = {}\n",
    "    for col in col_list:\n",
    "        quantiles = df_outliers.approxQuantile(\n",
    "           col, [0.25, 0.75], 0.05\n",
    "       )\n",
    "        IQR = quantiles[1] - quantiles[0]\n",
    "        bounds[col] = [\n",
    "           quantiles[0] - 1.5 * IQR,\n",
    "           quantiles[1] + 1.5 * IQR\n",
    "     ]\n",
    "    return bounds\n",
    "def getDFOutliers(df_outliers,bounds,cols,id_col):\n",
    "    'print all outlier rows based on dictionary with outlier bounderies dict, for columns in column list'\n",
    "    outliers = df_outliers.select(*[id_col] + [\n",
    "       (\n",
    "           (df_outliers[c] < bounds[c][0]) |\n",
    "           (df_outliers[c] > bounds[c][1])\n",
    "       ).alias(c + '_o') for c in cols\n",
    "    ])\n",
    "    return outliers\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Checking table duplicate rows =====\n",
      "Count of rows: 1391578\n",
      "Count of distinct rows: 1391071\n",
      "===> nr of duplicate rows 507\n",
      "====Checking table duplicate rows =====\n",
      "Count of rows: 526\n",
      "Count of distinct rows: 526\n",
      "===> nr of duplicate rows 0\n",
      "====Checking table duplicate rows =====\n",
      "Count of rows: 114728\n",
      "Count of distinct rows: 113993\n",
      "===> nr of duplicate rows 735\n"
     ]
    }
   ],
   "source": [
    "#Check duplicates rows, same value?\n",
    "flights_df = spark.sql(\"select * from flights\") #507 out of 1.4 milj\n",
    "showDuplicateRowsCount(flights_df)\n",
    "airports_df = spark.sql(\"select * from airports\") #0\n",
    "showDuplicateRowsCount(airports_df)\n",
    "tracks_df = spark.sql(\"select * from tracks\") #192k out of 14m, 735 out of 114k after filtering for AMS arrival\n",
    "showDuplicateRowsCount(tracks_df) #takes 10 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pure duplicates just drop these, but the flights tables might be different flights. We donts know without id\n",
    "tracks_df =tracks_df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicate columns check\n",
    "\n",
    "Some times there are columns identifying a row, and which are different.\n",
    "However in case you know the rest of the columns is the same you might want to remove these rows. eg , Michel , 1.90, hoofddorp , and michel2, 1.90, hoofddorp . Its the same person but id is incorrect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Checking col IATA\n",
      "Count of values: 526\n",
      "Count of distinct column values: 511\n",
      "====> duplicate count 15\n",
      "+-----+--------+\n",
      "|count|distinct|\n",
      "+-----+--------+\n",
      "|  526|     524|\n",
      "+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#airports IATA should be uniq. It seems 15 rows have identical data \n",
    "#but different IATA code\n",
    "showDuplicatesColumnCount(airports_df,'IATA')\n",
    "showDuplicatesColumnCountSpark(airports_df,'IATA')\n",
    "#TODO WHY ARE RESULT DIFFERENT!!!!!! SHOULD BE BOTH 511 OR 524!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Checking col flight\n",
      "Count of values: 113993\n",
      "Count of distinct column values: 113993\n",
      "====> duplicate count 0\n"
     ]
    }
   ],
   "source": [
    "showDuplicatesColumnCount(tracks_df,'flight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "We could call dropDuplicateColumn(df_airports,'IATA')\n",
    "\n",
    "However this would delete rows without knowing the correct IATA. \n",
    "The Flights tables does not have uniq field like flightname,\n",
    "so will not delete any rows there either.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO: Make function to show these rows so we know which are duplicates\n",
    "#df_duplicate_airports = getDFDuplicateColumns(airports_df,'IATA','new_id')\n",
    "#df_duplicate_airports.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing data\n",
    "\n",
    "```\n",
    "Drop data row if possible in case of missing. if datasize. < 50% check which features are missing, and just drop these.\n",
    "Alternative impute missing:\n",
    "Boolean: add missing category\n",
    "categorial already: add multiple extra levels and and missing there\n",
    "numeric and ordinal: mean, median etc to fill in\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+---------------+------------+\n",
      "|City_missing|State_missing|Country_missing|IATA_missing|\n",
      "+------------+-------------+---------------+------------+\n",
      "|         0.0|          0.0|            0.0|         0.0|\n",
      "+------------+-------------+---------------+------------+\n",
      "\n",
      "+------------+-------------+----------------+--------------+-------------------+\n",
      "|date_missing|delay_missing|distance_missing|origin_missing|destination_missing|\n",
      "+------------+-------------+----------------+--------------+-------------------+\n",
      "|         0.0|          0.0|             0.0|           0.0|                0.0|\n",
      "+------------+-------------+----------------+--------------+-------------------+\n",
      "\n",
      "+----------+----------------+------------+---------------+--------------------+-----------+--------------+------------+-----------+-----------+--------------------+-----------+-----------+--------------------+--------------------+-----------+-----------+-----------------+-----------+\n",
      "|na_missing|altitude_missing|dest_missing|heading_missing|      flight_missing|na2_missing|landed_missing|time_missing|lat_missing|lon_missing|         na3_missing|org_missing|na4_missing|registration_missing|     flight2_missing|na5_missing|na6_missing|planetype_missing|na7_missing|\n",
      "+----------+----------------+------------+---------------+--------------------+-----------+--------------+------------+-----------+-----------+--------------------+-----------+-----------+--------------------+--------------------+-----------+-----------+-----------------+-----------+\n",
      "|       0.0|             0.0|         0.0|            0.0|0.006044230786100946|        0.0|           0.0|         0.0|        0.0|        0.0|2.631740545466776...|        0.0|        0.0|2.631740545466776...|0.001175510776977...|        0.0|        0.0|              0.0|        0.0|\n",
      "+----------+----------------+------------+---------------+--------------------+-----------+--------------+------------+-----------+-----------+--------------------+-----------+-----------+--------------------+--------------------+-----------+-----------+-----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#0 = perfect, 1 = all is missing\n",
    "showMissingDataPercent(airports_df) #State misses some data\n",
    "showMissingDataPercent(flights_df)\n",
    "showMissingDataPercent(tracks_df) #We miss some, flight a bit, but is important to have these,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------------+------------+\n",
      "|City_missing|Country_missing|IATA_missing|\n",
      "+------------+---------------+------------+\n",
      "|         0.0|            0.0|         0.0|\n",
      "+------------+---------------+------------+\n",
      "\n",
      "+----------+----------------+------------+---------------+-----------+--------------+------------+-----------+-----------+--------------------+-----------+-----------+--------------------+--------------------+-----------+-----------+-----------------+-----------+\n",
      "|na_missing|altitude_missing|dest_missing|heading_missing|na2_missing|landed_missing|time_missing|lat_missing|lon_missing|         na3_missing|org_missing|na4_missing|registration_missing|     flight2_missing|na5_missing|na6_missing|planetype_missing|na7_missing|\n",
      "+----------+----------------+------------+---------------+-----------+--------------+------------+-----------+-----------+--------------------+-----------+-----------+--------------------+--------------------+-----------+-----------+-----------------+-----------+\n",
      "|       0.0|             0.0|         0.0|            0.0|        0.0|           0.0|         0.0|        0.0|        0.0|2.631740545466776...|        0.0|        0.0|2.631740545466776...|0.001175510776977...|        0.0|        0.0|              0.0|        0.0|\n",
      "+----------+----------------+------------+---------------+-----------+--------------+------------+-----------+-----------+--------------------+-----------+-----------+--------------------+--------------------+-----------+-----------+-----------------+-----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "113993"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We could just drop column state, we keep all our rows, and have no missing data\n",
    "df_no_state = getDFDropColumn(airports_df,'State')\n",
    "showMissingDataPercent(df_no_state)\n",
    "\n",
    "df_no_flight = getDFDropColumn(tracks_df,'flight')\n",
    "showMissingDataPercent(df_no_flight)\n",
    "\n",
    "df_no_flight.count() #113993 out of 114k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+---------------+------------+\n",
      "|City_missing|State_missing|Country_missing|IATA_missing|\n",
      "+------------+-------------+---------------+------------+\n",
      "|         0.0|          0.0|            0.0|         0.0|\n",
      "+------------+-------------+---------------+------------+\n",
      "\n",
      "+----------+----------------+------------+---------------+--------------+-----------+--------------+------------+-----------+-----------+-----------+-----------+-----------+--------------------+---------------+-----------+-----------+-----------------+-----------+\n",
      "|na_missing|altitude_missing|dest_missing|heading_missing|flight_missing|na2_missing|landed_missing|time_missing|lat_missing|lon_missing|na3_missing|org_missing|na4_missing|registration_missing|flight2_missing|na5_missing|na6_missing|planetype_missing|na7_missing|\n",
      "+----------+----------------+------------+---------------+--------------+-----------+--------------+------------+-----------+-----------+-----------+-----------+-----------+--------------------+---------------+-----------+-----------+-----------------+-----------+\n",
      "|       0.0|             0.0|         0.0|            0.0|           0.0|        0.0|           0.0|         0.0|        0.0|        0.0|        0.0|        0.0|        0.0|                 0.0|            0.0|        0.0|        0.0|              0.0|        0.0|\n",
      "+----------+----------------+------------+---------------+--------------+-----------+--------------+------------+-----------+-----------+-----------+-----------+-----------+--------------------+---------------+-----------+-----------+-----------------+-----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "113167"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Or drop only rows with any missing data\n",
    "df_without_missing = getDFDropMissingRows(airports_df)\n",
    "showMissingDataPercent(df_without_missing)\n",
    "\n",
    "df_without_missing_flight = getDFDropMissingRows(tracks_df)\n",
    "showMissingDataPercent(df_without_missing_flight)\n",
    "\n",
    "df_without_missing_flight.count() #Also 113167 , so we could just use this for the tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+-------+----+\n",
      "|         City|  State|Country|IATA|\n",
      "+-------------+-------+-------+----+\n",
      "|Washington DC|missing|    USA| IAD|\n",
      "|Washington DC|missing|    USA| DCA|\n",
      "|Washington DC|missing|    USA| WAS|\n",
      "+-------------+-------+-------+----+\n",
      "\n",
      "+------------+-------------+---------------+------------+\n",
      "|City_missing|State_missing|Country_missing|IATA_missing|\n",
      "+------------+-------------+---------------+------------+\n",
      "|         0.0|          0.0|            0.0|         0.0|\n",
      "+------------+-------------+---------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Or we can impute values, as this is a category we will add a missing category\n",
    "df_missing_state = getDFFillMissingCategoryColumn(airports_df,'State')\n",
    "df_missing_state.where(\"State == 'missing'\").show() #3\n",
    "df_missing_state.count() #526\n",
    "showMissingDataPercent(df_missing_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#LETS PICK LAST OPTION for Airports and trackers\n",
    "airports_df = df_missing_state\n",
    "tracker_df = df_without_missing_flight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### outliers\n",
    "\n",
    "Outliers are those observations that deviate signi cantly from the distribution of the rest of your sample. The de nitions of signi cance vary, but in the most general form, you can accept that there are no outliers if all the values are roughly within the Q1−1.5IQR and Q3+1.5IQR range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'distance': [-524.5, 1823.5], 'delay': [-34.0, 46.0]}\n",
      "{'landed': [0.0, 0.0], 'heading': [-280.5, 651.5], 'lon': [-35.0, 61.0], 'lat': [33.0, 65.0], 'time': [1466680461.5, 1466861161.5], 'altitude': [-312.5, 59387.5]}\n"
     ]
    }
   ],
   "source": [
    "#Show the ouytlier ranges for our integer based columns\n",
    "col_list = ['delay','distance'] \n",
    "\n",
    "outliers_dict = getDictOutliers(flights_df,col_list)\n",
    "print(outliers_dict) \n",
    "\n",
    "#Show the ouytlier ranges for our integer based columns\n",
    "col_list = ['lat','lon','altitude','heading','time','landed'] \n",
    "\n",
    "outliers_flights_dict = getDictOutliers(tracks_df,col_list)\n",
    "print(outliers_flights_dict) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Flag rows\n",
    "df_outliers = getDFOutliers(flights_df,outliers_dict,col_list,'id')\n",
    "df_outliers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#1.4 milj flights, about 162k has outlier delays. And 75k outlier distance\n",
    "df_out= flights_df.join(df_outliers, on='id')\n",
    "print(df_out.filter('delay_o').select('id', 'delay').count()) #162K\n",
    "print(df_out.filter('distance_o').select('id', 'distance').count()) #75K\n",
    "df_out.filter('delay_o').select('id', 'delay').show()\n",
    "df_out.filter('distance_o').select('id', 'distance').show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#read in the file\n",
    "flights = \"file:/root/learningPySpark/Chapter03/flight-data/departuredelays.csv\" \n",
    "fl = sc.textFile(flights) #you can use .gz, so better then spark sql\n",
    "header = fl.first()\n",
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#Filter numeric columns in flights\n",
    "fl_filter = fl.filter(lambda row: row != header) \\\n",
    "       .map(lambda row: [int(elem) for elem in row.split(',') if (elem.isdigit() or elem.lstrip(\"-\").isdigit()) ])\n",
    "fl_filter.take(5) #.foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create schema\n",
    "fields = [ *[\n",
    "           typ.StructField(h[1:-1], typ.IntegerType(), True)\n",
    "           for h in header.split(',')\n",
    "       ]\n",
    "   ]\n",
    "schema = typ.StructType(fields)\n",
    "schema   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create DF Spark\n",
    "fli_df = spark.createDataFrame(fl_filter, schema)\n",
    "fli_df.printSchema()\n",
    "#fli_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark",
   "language": "python",
   "name": "spark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
