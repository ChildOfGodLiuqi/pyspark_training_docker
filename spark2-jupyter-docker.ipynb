{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Docker Spark setup\n",
    "\n",
    "This notebook is meant to run on a spark 2 docker container. First i'll describe the steps to set it up.\n",
    "\n",
    "On a Linux based system install Docker and Docker-compose.Create this file : docker-compose.yml. The contents is listed below.  Then run: docker-compose build . Afterwards run this command : docker-compose build -d\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "```\n",
    "version: \"2\"\n",
    "\n",
    "services:\n",
    "  master:\n",
    "    image: singularities/spark\n",
    "    command: start-spark master\n",
    "    hostname: master\n",
    "    ports:\n",
    "      - \"6066:6066\"\n",
    "      - \"7070:7070\"\n",
    "      - \"8080:8080\"\n",
    "      - \"50070:50070\"\n",
    "      - \"8888:8888\"\n",
    "  worker:\n",
    "    image: singularities/spark\n",
    "    command: start-spark worker master\n",
    "    environment:\n",
    "      SPARK_WORKER_CORES: 1\n",
    "      SPARK_WORKER_MEMORY: 2g\n",
    "    links:\n",
    "      - master\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "```\n",
    "With docker ps , check if the master and worker containers are running.\n",
    "Connect to the master node:\n",
    "docker exec -it [container id master] bash\n",
    "On the master node continue with setting up as described below.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Spark and conda env setup\n",
    "\n",
    "```\n",
    "First install Anaconda 4 (latest version) on the Docker container with Spark Master. Then install a new Conda environment for Spark, using python 3.5 (3.6 has a bug).  \n",
    "\n",
    "conda create -n spark python=3.5\n",
    "source activate spark\n",
    "conda install notebook ipykernel\n",
    "ipython kernel install --user --name spark --display-name spark\n",
    "\n",
    "Make jupyter start script, and run it:\n",
    "PYSPARK_PYTHON=/root/anaconda3/envs/spark/bin/python\n",
    "PYSPARK_DRIVER_PYTHON=jupyter PYSPARK_DRIVER_PYTHON_OPTS='notebook --ip=0.0.0.0 --port=8888' $SPARK_HOME/bin/pyspark\n",
    "\n",
    "Now go to the url it gives (http://0.0.0.0:8888/<some code>)\n",
    ", Run the nodebook sections.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Start this in spark conda env to test\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "import pyspark.sql.functions as fn\n",
    "import pyspark.sql.types as typ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Example data\n",
    "\n",
    "```\n",
    "This example works if you clone https://github.com/PacktPublishing/Learning-PySpark\n",
    "\n",
    "and make sure its in /root/learningPySpark on the Docker container with Spark Master. \n",
    "\n",
    "To install git on this container run command: apt-get install git\n",
    ", on github (or bitbucket) create a repository so you can save changes from the container and push it to Github. Use the following commands on the Docker container to init and push the data :\n",
    "\n",
    "git init\n",
    "git add <your file>\n",
    "git commit -m \"first commit\"\n",
    "git remote add origin https://github.com/michelnossin/pyspark_training_docker.git\n",
    "git push -u origin master\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[date: string, delay: string, distance: string, origin: string, destination: string]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RANDOM FLIGHTS SET, AND WORLD AIRPORT SET\n",
    "flights = \"file:/root/learningPySpark/Chapter03/flight-data/departuredelays.csv\" \n",
    "airports = \"file:/root/learningPySpark/Chapter03/flight-data/airport-codes-na.txt\" \n",
    "airports_df = spark.read.csv(airports,header='true',inferSchema='true',sep='\\t')\n",
    "airports_df.createOrReplaceTempView(\"airports\")\n",
    "flights_df = spark.read.csv(flights,header='true')\n",
    "flights_df.createOrReplaceTempView(\"flights\")\n",
    "flights_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[na: string, altitude: string, dest: string, heading: string, flight: string, fltid: string, landed: string, time: string, lat: string, lon: string, na3: string, org: string, na4: string, registration: string, flight2: string, speed: string, na6: string, planetype: string, altitude_delta: string]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RADAR TRACK\n",
    "track_file = \"file:/root/fr24/fr24_20160624.csv\"\n",
    "header=['na','altitude','dest','heading','flight','fltid','landed','time','lat',\\\n",
    "         'lon','na3','org','na4','registration','flight2','speed','na6','planetype', 'altitude_delta']\n",
    "fields = [ *[\n",
    "           typ.StructField(h, typ.StringType(), True)\n",
    "           for h in header\n",
    "       ]\n",
    "   ]\n",
    "schema = typ.StructType(fields)\n",
    "schema   \n",
    "tracks_df = spark.read.csv(track_file,header='false',schema=schema)\n",
    "\n",
    "#filter tracks early to make it speed up\n",
    "tracks_df = tracks_df.where(\"dest == 'AMS'\") #14 milj -> 114k\n",
    "tracks_df.createOrReplaceTempView(\"tracks\")\n",
    "tracks_df.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Alternatively use correct schema from beginning:\n",
    "import pyspark.sql.types as typ\n",
    "   labels = [\n",
    "       ('INFANT_ALIVE_AT_REPORT', typ.IntegerType()),\n",
    "       ('BIRTH_PLACE', typ.StringType()),\n",
    "       ('MOTHER_AGE_YEARS', typ.IntegerType()),\n",
    "       ('FATHER_COMBINED_AGE', typ.IntegerType()),\n",
    "       ('CIG_BEFORE', typ.IntegerType()),\n",
    "       ('CIG_1_TRI', typ.IntegerType()),\n",
    "       ('CIG_2_TRI', typ.IntegerType()),\n",
    "       ('CIG_3_TRI', typ.IntegerType()),\n",
    "       ('MOTHER_HEIGHT_IN', typ.IntegerType()),\n",
    "       ('MOTHER_PRE_WEIGHT', typ.IntegerType()),\n",
    "       ('MOTHER_DELIVERY_WEIGHT', typ.IntegerType()),\n",
    "       ('MOTHER_WEIGHT_GAIN', typ.IntegerType()),\n",
    "       ('DIABETES_PRE', typ.IntegerType()),\n",
    "       ('DIABETES_GEST', typ.IntegerType()),\n",
    "       ('HYP_TENS_PRE', typ.IntegerType()),\n",
    "       ('HYP_TENS_GEST', typ.IntegerType()),\n",
    "       ('PREV_BIRTH_PRETERM', typ.IntegerType())\n",
    "   ]\n",
    "   schema = typ.StructType([\n",
    "       typ.StructField(e[0], e[1], False) for e in labels\n",
    "   ])\n",
    "   births = spark.read.csv('births_transformed.csv.gz',\n",
    "                           header=True,\n",
    "                           schema=schema)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## First look at data:\n",
    "\n",
    "```\n",
    "source activate spark\n",
    "python -m pip install pandas\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark.sql(\"select count(1) from flights\").show()\n",
    "spark.sql(\"select count(1) from airports\").show()\n",
    "spark.sql(\"select count(1) from tracks\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "flights_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "airports_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tracks_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "airports_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "flights_df.printSchema() #date, delay and distance should change to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tracks_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Cleaning data\n",
    "\n",
    "Your data can be stained with duplicates, missing observations and outliers, non- existent addresses, wrong phone numbers and area codes, inaccurate geographical coordinates, wrong dates, incorrect labels, mixtures of upper and lower cases, trailing spaces, and many other more subtle problems. It is your job to clean it, irrespective of whether you are a data scientist or data engineer,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Duplicate rows check and remove\n",
    "First lets define some our spark util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def showDuplicateRowsCount(df):\n",
    "    'Show row count with full duplicated rows'\n",
    "    print(\"====Checking table duplicate rows =====\")\n",
    "    print('Count of rows: {0}'.format(df.count()))\n",
    "    print('Count of distinct rows: {0}'.format(df.distinct().count()))\n",
    "    print('===> nr of duplicate rows {0}'.format(df.count()-df.distinct().count()))\n",
    "def showDuplicatesColumnCount(df,col):\n",
    "    'Show duplicate rows based on a specific (id) col.'\n",
    "    print(\"=====Checking col {0}\".format(col))\n",
    "    print('Count of values: {0}'.format(df.count()))\n",
    "    distinct_col_count = df.select([\n",
    "           c for c in df.columns if c != col\n",
    "       ]).distinct().count()\n",
    "    print('Count of distinct column values: {0}'.format(distinct_col_count))\n",
    "    print (\"====> duplicate count {0}\".format(df.count() - distinct_col_count))\n",
    "def showDuplicatesColumnCountSpark(df,col):\n",
    "    'spark version of Showduplicatescolumncount()'\n",
    "    df.agg(\n",
    "       fn.count(col).alias('count'),\n",
    "       fn.countDistinct(col).alias('distinct')\n",
    "    ).show()\n",
    "def showDuplicateColumnsCount(df):\n",
    "    'Show duplicate rows based on all columns in a dataframe'\n",
    "    for col in df.columns:\n",
    "        showDuplicatesColumn(df,col)\n",
    "def dropDuplicateColumn(df,col):\n",
    "    'drop rows with duplicate columns based on certain (id) column'\n",
    "    df = df.dropDuplicates(subset=[\n",
    "       c for c in df.columns if c != col\n",
    "    ])\n",
    "#   \n",
    "#def getDFDuplicateColumns(df,col,new_col):\n",
    "#    uniq_df = df.select([\n",
    "#           c for c in df.columns if c != col\n",
    "#       ]).distinct()\n",
    "#    duplicate_df = df.subtract(uniq_df)\n",
    "#    \n",
    "#    return(duplicate_df.withColumn(new_col, \\\n",
    "#                            fn.monotonically_increasing_id()))\n",
    "#   **/ \n",
    "def showMissingDataPercent(df_miss):\n",
    "    'show each column and percentage of missing data, 0 - 1 , 0 means no missing data'\n",
    "    df_miss.agg(*[\n",
    "       (1 - (fn.count(c) / fn.count('*'))).alias(c + '_missing')\n",
    "       for c in df_miss.columns\n",
    "    ]).show()\n",
    "def getDFDropColumn(df_miss,col):\n",
    "    'Get a new dataframe based on another without given column'\n",
    "    return(df_miss.select([\n",
    "       c for c in df_miss.columns if c != col\n",
    "    ]))\n",
    "def getDFDropMissingRows(df_miss):\n",
    "    'Drop rows with any missing column field'\n",
    "    return(df_miss.dropna())\n",
    "def fillMissingMeanColumn(df,col):\n",
    "    'Fill in missing values in a certain column containing numerical data'\n",
    "    means = df.agg(\n",
    "       *[fn.mean(col).alias(col)\n",
    "           for c in df.columns if c != col]\n",
    "   ).toPandas().to_dict('records')[0]\n",
    "def getDFFillMissingCategoryColumn(df,col):\n",
    "    'Fill in missing values in a column containing a category and return df'\n",
    "    miss_dict = {col: \"missing\"}\n",
    "    return(df.fillna(miss_dict))\n",
    "def getDictOutliers(df_outliers,col_list):\n",
    "    'return dictionary with outliers boundaries , based on columns in list'\n",
    "    bounds = {}\n",
    "    for col in col_list:\n",
    "        quantiles = df_outliers.approxQuantile(\n",
    "           col, [0.25, 0.75], 0.05\n",
    "       )\n",
    "        IQR = quantiles[1] - quantiles[0]\n",
    "        bounds[col] = [\n",
    "           quantiles[0] - 1.5 * IQR,\n",
    "           quantiles[1] + 1.5 * IQR\n",
    "     ]\n",
    "    return bounds\n",
    "def getDFOutliers(df_outliers,bounds,cols,id_col):\n",
    "    'print all outlier rows based on dictionary with outlier bounderies dict, for columns in column list'\n",
    "    outliers = df_outliers.select(*[id_col] + [\n",
    "       (\n",
    "           (df_outliers[c] < bounds[c][0]) |\n",
    "           (df_outliers[c] > bounds[c][1])\n",
    "       ).alias(c + '_o') for c in cols\n",
    "    ])\n",
    "    return outliers\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Check duplicates rows, same value?\n",
    "flights_df = spark.sql(\"select * from flights\") #507 out of 1.4 milj\n",
    "showDuplicateRowsCount(flights_df)\n",
    "airports_df = spark.sql(\"select * from airports\") #0\n",
    "showDuplicateRowsCount(airports_df)\n",
    "tracks_df = spark.sql(\"select * from tracks\") #192k out of 14m, 735 out of 114k after filtering for AMS arrival\n",
    "showDuplicateRowsCount(tracks_df) #takes 10 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Change type of integer based columns , so we check outliers later on\n",
    "flights_df = flights_df.withColumn(\"delay\",flights_df[\"delay\"].cast(typ.IntegerType()))\n",
    "flights_df = flights_df.withColumn(\"distance\",flights_df[\"distance\"].cast(typ.IntegerType()))\n",
    "                   \n",
    "tracks_df = tracks_df.withColumn(\"altitude\",tracks_df[\"altitude\"].cast(typ.IntegerType()))  \n",
    "tracks_df = tracks_df.withColumn(\"altitude_delta\",tracks_df[\"altitude_delta\"].cast(typ.IntegerType()))\n",
    "tracks_df = tracks_df.withColumn(\"speed\",tracks_df[\"speed\"].cast(typ.IntegerType()))      \n",
    "tracks_df = tracks_df.withColumn(\"heading\",tracks_df[\"heading\"].cast(typ.IntegerType()))   \n",
    "tracks_df = tracks_df.withColumn(\"lat\",tracks_df[\"lat\"].cast(typ.FloatType()))  \n",
    "tracks_df = tracks_df.withColumn(\"lon\",tracks_df[\"lon\"].cast(typ.FloatType())) \n",
    "tracks_df = tracks_df.withColumn(\"time\",tracks_df[\"time\"].cast(typ.LongType())) \n",
    "tracks_df = tracks_df.withColumn(\"landed\",tracks_df[\"landed\"].cast(typ.IntegerType()))\n",
    "\n",
    "#Lets add a id columns for the flights\n",
    "flights_df = flights_df.withColumn('id',fn.monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#pure duplicates just drop these, but the flights tables might be different flights. We donts know without id\n",
    "tracks_df =tracks_df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Duplicate columns check\n",
    "\n",
    "Some times there are columns identifying a row, and which are different.\n",
    "However in case you know the rest of the columns is the same you might want to remove these rows. eg , Michel , 1.90, hoofddorp , and michel2, 1.90, hoofddorp . Its the same person but id is incorrect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#airports IATA should be uniq. It seems 15 rows have identical data \n",
    "#but different IATA code\n",
    "showDuplicatesColumnCount(airports_df,'IATA')\n",
    "showDuplicatesColumnCountSpark(airports_df,'IATA')\n",
    "#TODO WHY ARE RESULT DIFFERENT!!!!!! SHOULD BE BOTH 511 OR 524!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "showDuplicatesColumnCount(tracks_df,'flight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "```\n",
    "We could call dropDuplicateColumn(df_airports,'IATA')\n",
    "\n",
    "However this would delete rows without knowing the correct IATA. \n",
    "The Flights tables does not have uniq field like flightname,\n",
    "so will not delete any rows there either.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#TODO: Make function to show these rows so we know which are duplicates\n",
    "#df_duplicate_airports = getDFDuplicateColumns(airports_df,'IATA','new_id')\n",
    "#df_duplicate_airports.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Missing data\n",
    "\n",
    "```\n",
    "Drop data row if possible in case of missing. if datasize. < 50% check which features are missing, and just drop these.\n",
    "Alternative impute missing:\n",
    "Boolean: add missing category\n",
    "categorial already: add multiple extra levels and and missing there\n",
    "numeric and ordinal: mean, median etc to fill in\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#0 = perfect, 1 = all is missing\n",
    "showMissingDataPercent(airports_df) #State misses some data\n",
    "showMissingDataPercent(flights_df)\n",
    "showMissingDataPercent(tracks_df) #We miss some, flight a bit, but is important to have these,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#We could just drop column state, we keep all our rows, and have no missing data\n",
    "df_no_state = getDFDropColumn(airports_df,'State')\n",
    "showMissingDataPercent(df_no_state)\n",
    "\n",
    "df_no_flight = getDFDropColumn(tracks_df,'flight')\n",
    "showMissingDataPercent(df_no_flight)\n",
    "\n",
    "df_no_flight.count() #113993 out of 114k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+---------------+------------+\n",
      "|City_missing|State_missing|Country_missing|IATA_missing|\n",
      "+------------+-------------+---------------+------------+\n",
      "|         0.0|          0.0|            0.0|         0.0|\n",
      "+------------+-------------+---------------+------------+\n",
      "\n",
      "+----------+----------------+------------+---------------+--------------+-------------+--------------+------------+-----------+-----------+-----------+-----------+-----------+--------------------+---------------+-------------+-----------+-----------------+----------------------+\n",
      "|na_missing|altitude_missing|dest_missing|heading_missing|flight_missing|fltid_missing|landed_missing|time_missing|lat_missing|lon_missing|na3_missing|org_missing|na4_missing|registration_missing|flight2_missing|speed_missing|na6_missing|planetype_missing|altitude_delta_missing|\n",
      "+----------+----------------+------------+---------------+--------------+-------------+--------------+------------+-----------+-----------+-----------+-----------+-----------+--------------------+---------------+-------------+-----------+-----------------+----------------------+\n",
      "|       0.0|             0.0|         0.0|            0.0|           0.0|          0.0|           0.0|         0.0|        0.0|        0.0|        0.0|        0.0|        0.0|                 0.0|            0.0|          0.0|        0.0|              0.0|                   0.0|\n",
      "+----------+----------------+------------+---------------+--------------+-------------+--------------+------------+-----------+-----------+-----------+-----------+-----------+--------------------+---------------+-------------+-----------+-----------------+----------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "113167"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Or drop only rows with any missing data\n",
    "df_without_missing = getDFDropMissingRows(airports_df)\n",
    "showMissingDataPercent(df_without_missing)\n",
    "\n",
    "df_without_missing_flight = getDFDropMissingRows(tracks_df)\n",
    "showMissingDataPercent(df_without_missing_flight)\n",
    "\n",
    "df_without_missing_flight.count() #Also 113167 , so we could just use this for the tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+-------+----+\n",
      "|         City|  State|Country|IATA|\n",
      "+-------------+-------+-------+----+\n",
      "|Washington DC|missing|    USA| IAD|\n",
      "|Washington DC|missing|    USA| DCA|\n",
      "|Washington DC|missing|    USA| WAS|\n",
      "+-------------+-------+-------+----+\n",
      "\n",
      "+------------+-------------+---------------+------------+\n",
      "|City_missing|State_missing|Country_missing|IATA_missing|\n",
      "+------------+-------------+---------------+------------+\n",
      "|         0.0|          0.0|            0.0|         0.0|\n",
      "+------------+-------------+---------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Or we can impute values, as this is a category we will add a missing category\n",
    "df_missing_state = getDFFillMissingCategoryColumn(airports_df,'State')\n",
    "df_missing_state.where(\"State == 'missing'\").show() #3\n",
    "df_missing_state.count() #526\n",
    "showMissingDataPercent(df_missing_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#LETS PICK LAST OPTION for Airports and trackers\n",
    "airports_df = df_missing_state\n",
    "tracks_df = df_without_missing_flight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### outliers\n",
    "\n",
    "Outliers are those observations that deviate signi cantly from the distribution of the rest of your sample. The de nitions of signi cance vary, but in the most general form, you can accept that there are no outliers if all the values are roughly within the Q1−1.5IQR and Q3+1.5IQR range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Show the ouytlier ranges for our integer based columns\n",
    "col_list = ['delay','distance'] \n",
    "\n",
    "#Run cast code in the beginning again (dont no why thats needed?)\n",
    "outliers_dict = getDictOutliers(flights_df,col_list)\n",
    "print(outliers_dict) \n",
    "\n",
    "#Show the ouytlier ranges for our integer based columns\n",
    "col_flights_list = ['lat','lon','altitude','heading','time','landed'] \n",
    "\n",
    "outliers_flights_dict = getDictOutliers(tracks_df,col_flights_list)\n",
    "print(outliers_flights_dict) #Not really handy way to check outliers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Flag rows\n",
    "#Run the id add function again, for some reason..\n",
    "df_outliers = getDFOutliers(flights_df,outliers_dict,col_list,'id')\n",
    "df_outliers.show()\n",
    "\n",
    "df_flight_outliers = getDFOutliers(tracks_df,outliers_flights_dict,col_flights_list,'flight')\n",
    "df_flight_outliers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Show outlier  flights\n",
    "#1.4 milj flights, about 162k has outlier delays. And 75k outlier distance\n",
    "df_out= flights_df.join(df_outliers, on='id')\n",
    "print(df_out.filter('delay_o').select('id', 'delay').count())\n",
    "print(df_out.filter('distance_o').select('id', 'distance').count())\n",
    "df_out.filter('delay_o').select('id', 'delay').show()\n",
    "df_out.filter('distance_o').select('id', 'distance').show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Show outlier  tracks, dont understand the result yet .. todo\n",
    "df_out=tracks_df.join(df_flight_outliers, on='flight')\n",
    "print(df_out.filter('heading_o').select('flight', 'heading').count())  #None, however heading has strange values\n",
    "print(df_out.filter('altitude_o').select('flight', 'altitude').count()) #None, but shows some strange numbers\n",
    "print(df_out.filter('lat_o').select('flight', 'lat').count()) #32, < 33 but still good value\n",
    "print(df_out.filter('lon_o').select('flight', 'lon').count()) #-66 also good\n",
    "print(df_out.filter('landed_o').select('flight', 'landed').count())  # 0 , <> 0.0 .. \n",
    "\n",
    "df_out.filter('heading_o').select('flight', 'heading').show()\n",
    "df_out.filter('altitude_o').select('flight', 'altitude').show()\n",
    "df_out.filter('lat_o').select('flight', 'lat').show()\n",
    "df_out.filter('lon_o').select('flight', 'lon').show()\n",
    "df_out.filter('landed_o').select('flight', 'landed').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Lets filters in between known ranges:\n",
    "#landed 0 or 1\n",
    "#heading 0 - 360\n",
    "#altitude < 100 , > 50000 \n",
    "#the valid range of latitude in degrees is -90 and +90 . Longitude is in the range -180 and +180 \n",
    "tracks_df = tracks_df.where(\"landed == 0 or landed == 1\")\n",
    "tracks_df = tracks_df.where(\"heading >= 0 and heading < 360\")\n",
    "tracks_df = tracks_df.where(\"altitude > -100 and altitude < 50000\")\n",
    "tracks_df = tracks_df.where(\"lat >= -90 and lat <= 90\")\n",
    "tracks_df = tracks_df.where(\"lon >= -180 and lon <= 180\")\n",
    "tracks_df.count() #only 1 row removed 113992\n",
    "\n",
    "tracks_df.describe().toPandas() #looks fine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Example flight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_sel = tracks_df.where(\"flight == 'KL836'\").toPandas().sort_values(['time']).reset_index() #515 rows\n",
    "df_sel.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import folium\n",
    "\n",
    "%matplotlib inline\n",
    "def inline_map(map):\n",
    "    \"\"\"\n",
    "    Embeds the HTML source of the map directly into the IPython notebook.\n",
    "    \n",
    "    This method will not work if the map depends on any files (json data). Also this uses\n",
    "    the HTML5 srcdoc attribute, which may not be supported in all browsers.\n",
    "    \"\"\"\n",
    "    map._build_map()\n",
    "    return HTML('<iframe srcdoc=\"{srcdoc}\" style=\"width: 100%; height: 510px; border: none\"></iframe>'.format(srcdoc=map.HTML.replace('\"', '&quot;')))\n",
    " \n",
    "def embed_map(map, path=\"map.html\"):\n",
    "    \"\"\"\n",
    "    Embeds a linked iframe to the map into the IPython notebook.\n",
    "    \n",
    "    Note: this method will not capture the source of the map into the notebook.\n",
    "    This method should work for all maps (as long as they use relative urls).\n",
    "    \"\"\"\n",
    "    map.create_map(path=path)\n",
    "    return HTML('<iframe src=\"files/{path}\" style=\"width: 100%; height: 510px; border: none\"></iframe>'.format(path=path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "#matplotlib.style.use('ggplot')\n",
    "df_sel[['altitude','speed']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import folium\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "def display(m, height=300):\n",
    "    \"\"\"Takes a folium instance and embed HTML.\"\"\"\n",
    "    m._build_map()\n",
    "    srcdoc = m.HTML.replace('\"', '&quot;')\n",
    "    embed = HTML('<iframe srcdoc=\"{0}\" '\n",
    "                 'style=\"width: 100%; height: {1}px; '\n",
    "                 'border: none\"></iframe>'.format(srcdoc, height))\n",
    "    return embed\n",
    "\n",
    "def inline_map(map):\n",
    "    \"\"\"\n",
    "    Embeds the HTML source of the map directly into the IPython notebook.\n",
    "    \n",
    "    This method will not work if the map depends on any files (json data). Also this uses\n",
    "    the HTML5 srcdoc attribute, which may not be supported in all browsers.\n",
    "    \"\"\"\n",
    "    map._build_map()\n",
    "    return HTML('<iframe srcdoc=\"{srcdoc}\" style=\"width: 100%; height: 510px; border: none\"></iframe>'.format(srcdoc=map.HTML.replace('\"', '&quot;')))\n",
    "\n",
    "def embed_map(map, path=\"map.html\"):\n",
    "    \"\"\"\n",
    "    Embeds a linked iframe to the map into the IPython notebook.\n",
    "    \n",
    "    Note: this method will not capture the source of the map into the notebook.\n",
    "    This method should work for all maps (as long as they use relative urls).\n",
    "    \"\"\"\n",
    "    #map.create_map(path=path)\n",
    "    return HTML('<iframe src=\"files/{path}\" style=\"width: 100%; height: 510px; border: none\"></iframe>'.format(path=path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import folium\n",
    "from IPython.display import HTML\n",
    "def plotFlight(flight):\n",
    "    #df_sel = tracks_df.where(\"flight == '\" + flight + \"'\").toPandas().sort_values(['time']).reset_index()\n",
    "    df_sel = join_df.toPandas().query(\"flight == '\" + flight + \"'\").sort_values(['time']).reset_index()\n",
    "    fmap=folium.Map(location=[52.308871, 4.761392], zoom_start=4)\n",
    "    #for row in df_sel.iterrows():\n",
    "     #   latlon = [ row[1]['lat'], row[1]['lon'] ]\n",
    "    #   folium.Marker(latlon, popup=str(row[1]['time'])).add_to(fmap)\n",
    "     #   fmap.add_children\n",
    "    \n",
    "    \n",
    "    latlist = df_sel['lat'].tolist()\n",
    "    lonlist = df_sel['lon'].tolist()\n",
    "    coordinates = zip(latlist[:], lonlist[:])\n",
    "    line=folium.PolyLine(locations=coordinates,weight=3,color = 'red')\n",
    "    fmap.add_children(line)\n",
    "    fmap.save('osm.html')\n",
    "    return HTML('<iframe src=\"files/{path}\" style=\"width: 100%; height: 510px; border: none\"></iframe>'.format(path='osm.html'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plotFlight('Y87486')\n",
    "#plotFlight('KL214')\n",
    "#plotFlight('KL836')\n",
    "#plotFlight('U26771')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#read in the file\n",
    "flights = \"file:/root/learningPySpark/Chapter03/flight-data/departuredelays.csv\" \n",
    "fl = sc.textFile(flights) #you can use .gz, so better then spark sql\n",
    "header = fl.first()\n",
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Filter numeric columns in flights\n",
    "fl_filter = fl.filter(lambda row: row != header) \\\n",
    "       .map(lambda row: [int(elem) for elem in row.split(',') if (elem.isdigit() or elem.lstrip(\"-\").isdigit()) ])\n",
    "fl_filter.take(5) #.foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#create schema\n",
    "fields = [ *[\n",
    "           typ.StructField(h, typ.IntegerType(), True)\n",
    "           for h in header.split(',')\n",
    "       ]\n",
    "   ]\n",
    "schema = typ.StructType(fields)\n",
    "schema   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#create DF Spark\n",
    "fli_df = spark.createDataFrame(fl_filter, schema)\n",
    "fli_df.printSchema()\n",
    "#fli_df.show() Some columns are not integer so crash, to fix later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#to group by values within a column\n",
    "tracks_df.groupby('flight').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#grouping the whole set and perform function\n",
    "tracks_df.agg({'speed' : 'skewness'}).show() #ratio mean to sd is very low, wide spread observation negatively\n",
    "\n",
    "#can also use: avg(), count(), countDistinct(), first(), kurtosis(), max(), mean(), min(), skewness(), stddev(), stddev_pop(), stddev_samp(), sum(), sumDistinct(), var_pop(), var_samp() and variance().\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#correlation is simple (only pearson , and in pairs)\n",
    "tracks_df.corr('landed','speed') #quit some relation which you expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def showCorrelationMatrix(df,numerical):\n",
    "    'for a DF print matrix with correlations between all numerical columns'\n",
    "    n_numerical = len(numerical)\n",
    "    corr = []\n",
    "    for i in range(0, n_numerical):\n",
    "        temp = [None] * i\n",
    "        for j in range(i, n_numerical):\n",
    "            temp.append(df.corr(numerical[i], numerical[j]))\n",
    "        corr.append(temp)\n",
    "        \n",
    "    print(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "showCorrelationMatrix(tracks_df,['speed','landed','altitude','heading'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tracks_df.corr('speed','altitude') #very high correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Lets try to make some features\n",
    "```\n",
    "Flight,time,speed,distance_to_ams,time_till_actual_landing\n",
    "\n",
    "distance to amsterdam , will be lat/lon comparison to lat/lon ams airport\n",
    "for each row\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from math import radians, cos, sin, asin, sqrt\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    km = 6367 * c\n",
    "    return km\n",
    "\n",
    "#This will be slow in pyspark due to context switching JVM and pyspark\n",
    "#Better to use UDF, or use Scala etc\n",
    "def dist_to_ams(lat,lon):\n",
    "    return haversine(float(4.761392), float(52.308871), float(lon),float(lat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def closest_runway(lon,lat,heading):\n",
    "    \"\"\" Get closest runway at amsterdam based on plane location and heading. return code 1-12 (6 runways * 2 headings)\"\"\"\n",
    "    \n",
    "    runway_list = [   { \"runway\" : 1, \"lat\" : 52.350202, \"lon\" : 4.710732 , \"heading1\" : 180 , \"heading2\" : 360, \"name\" : \"polderbaan\" },\n",
    "    { \"runway\" : 2, \"lat\" : 52.316110, \"lon\" : 4.738369 , \"heading1\" : 180 , \"heading2\" : 360, \"name\" : \"zwanenburgbaan\" },\n",
    "    { \"runway\" : 3, \"lat\" : 52.317579, \"lon\" : 4.772186 , \"heading1\" : 90 , \"heading2\" : 270, \"name\" : \"buitenveldertbaan\" },\n",
    "    { \"runway\" : 4, \"lat\" : 52.297217, \"lon\" : 4.757938 , \"heading1\" : 60 , \"heading2\" : 240, \"name\" : \"kaagbaan\" },\n",
    "    { \"runway\" : 5, \"lat\" : 52.307714, \"lon\" : 4.778881 , \"heading1\" : 180 , \"heading2\" : 360, \"name\" : \"aalsmeerbaan\" },\n",
    "    { \"runway\" : 6, \"lat\" : 52.308659, \"lon\" : 4.795361 , \"heading1\" : 40 , \"heading2\" : 220, \"name\" : \"oostbaan\" }\n",
    "]\n",
    "    \n",
    "    smallest_dist_runway = -1\n",
    "    smallest_dist = -1\n",
    "    for runway in runway_list:\n",
    "        dist = haversine(float(runway[\"lon\"]), float(runway[\"lat\"]), float(lon),float(lat))\n",
    "        if smallest_dist == -1 or dist < smallest_dist:\n",
    "            smallest_dist = dist\n",
    "            smallest_dist_runway = runway\n",
    "    \n",
    "    angle1 = 180 - abs(abs(heading - smallest_dist_runway[\"heading1\"]) - 180); \n",
    "    angle2 = 180 - abs(abs(heading - smallest_dist_runway[\"heading2\"]) - 180); \n",
    "    runway_code = smallest_dist_runway[\"runway\"]\n",
    "    \n",
    "    if angle1 < angle2 :\n",
    "        return runway_code\n",
    "    return runway_code + 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def closest_pier(lon,lat):\n",
    "    \"\"\" Get closest pier based on a location, used to predict on block time\"\"\"\n",
    "    pier_list = [\n",
    "        {\"id\" : 0 , \"pier\" : \"A\" , \"lon\" : 4.753781 , \"lat\" : 52.300381},\n",
    "        {\"id\" : 1 , \"pier\" : \"B\" , \"lon\" : 4.759363 , \"lat\" : 52.302362},\n",
    "        {\"id\" : 2 , \"pier\" : \"C\" , \"lon\" : 4.766188 , \"lat\" : 52.305380},\n",
    "        {\"id\" : 3 , \"pier\" : \"D\" , \"lon\" : 4.771575 , \"lat\" : 52.309147},\n",
    "        {\"id\" : 4 , \"pier\" : \"E\" , \"lon\" : 4.767366 , \"lat\" : 52.312182},\n",
    "        {\"id\" : 5 , \"pier\" : \"F\" , \"lon\" : 4.761679 , \"lat\" : 52.313040},\n",
    "        {\"id\" : 6 , \"pier\" : \"G\" , \"lon\" : 4.755998 , \"lat\" : 52.312574},\n",
    "        {\"id\" : 7 , \"pier\" : \"H\" , \"lon\" : 4.754054 , \"lat\" : 52.310135}\n",
    "    ]\n",
    "\n",
    "    smallest_dist_pier = -1\n",
    "    smallest_dist = -1\n",
    "    for pier in pier_list:\n",
    "        dist = haversine(float(pier[\"lon\"]), float(pier[\"lat\"]), float(lon),float(lat))\n",
    "        if smallest_dist == -1 or dist < smallest_dist:\n",
    "            smallest_dist = dist\n",
    "            smallest_dist_pier = pier\n",
    "            \n",
    "    return smallest_dist_pier[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def negative_to_zero(some_number):\n",
    "    if some_number < 0:\n",
    "        return 0\n",
    "    return some_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "udf_func = udf(dist_to_ams, FloatType())\n",
    "tracks_df = tracks_df.withColumn(\"distance_to_ams\", \\\n",
    "                            udf_func(tracks_df.lat,tracks_df.lon))\n",
    "\n",
    "udf_func2 = udf(closest_runway, IntegerType())\n",
    "udf_func3 = udf(negative_to_zero,IntegerType())\n",
    "udf_func4 = udf(closest_pier, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Distance is great, however, after landing, the next row is the NEXT\n",
    "# flight\n",
    "df = tracks_df.where(\"flight == 'KL214'\").toPandas().sort_values(['time']).reset_index()\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#just a test to compare rows\n",
    "from pyspark.sql.functions import col, lag\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "df = (\n",
    "    sc.parallelize([\n",
    "        (134, 30, \"2016-07-02 12:01:40\"), (134, 32, \"2016-07-02 12:21:23\"),\n",
    "        (125, 30, \"2016-07-02 13:22:56\"), (125, 32, \"2016-07-02 13:27:07\"),\n",
    "    ]).toDF([\"itemid\", \"eventid\", \"timestamp\"])\n",
    "    .withColumn(\"timestamp\", col(\"timestamp\").cast(\"timestamp\"))\n",
    ")\n",
    "\n",
    "w = Window.partitionBy(\"itemid\").orderBy(\"timestamp\")\n",
    "\n",
    "diff = col(\"timestamp\").cast(\"long\") - lag(\"timestamp\", 1).over(w).cast(\"long\")\n",
    "\n",
    "df = df.withColumn(\"diff\", diff)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Lets create a delta to get the landing times\n",
    "from pyspark.sql.functions import col, lag\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "df = (\n",
    "    sc.parallelize([\n",
    "        ('kl123', 0, \"2016-07-02 12:01:40\"), ('kl123', 0, \"2016-07-02 12:21:23\"),\n",
    "        ('kl123', 1, \"2016-07-02 13:22:56\"), ('kl123', 1, \"2016-07-02 13:27:07\"),\n",
    "    ]).toDF([\"itemid\", \"landed\", \"timestamp\"])\n",
    "    .withColumn(\"timestamp\", col(\"timestamp\").cast(\"timestamp\"))\n",
    ")\n",
    "\n",
    "w = Window.partitionBy(\"itemid\").orderBy(\"timestamp\")\n",
    "\n",
    "diff = col(\"landed\").cast(\"int\") - lag(\"landed\", 1).over(w).cast(\"int\")\n",
    "\n",
    "df = df.withColumn(\"diff\", diff)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+--------------+\n",
      "|flight_touchdown|runway_touchdown|time_touchdown|\n",
      "+----------------+----------------+--------------+\n",
      "|          CND518|               8|    1466792627|\n",
      "|           DL138|               1|    1466760692|\n",
      "|          MP6742|               1|    1466778285|\n",
      "|          KL1742|               2|    1466775981|\n",
      "|          U28881|               1|    1466793964|\n",
      "|          KL1134|               1|    1466796510|\n",
      "|          KL1800|               1|    1466801922|\n",
      "|          KL1858|               1|    1466777442|\n",
      "|           KL888|               1|    1466785238|\n",
      "|           OR288|               1|    1466767433|\n",
      "|          KL1618|               2|    1466749916|\n",
      "|          KL1790|               2|    1466749726|\n",
      "|           KL736|               1|    1466743064|\n",
      "|          U27908|               1|    1466800107|\n",
      "|          KL1168|               2|    1466775337|\n",
      "|          KL1010|               1|    1466769724|\n",
      "|           LH992|               1|    1466770692|\n",
      "|           LX736|               1|    1466799875|\n",
      "|           BT621|               2|    1466751644|\n",
      "|          U26771|               9|    1466763353|\n",
      "+----------------+----------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#now lets adds column to show the landing moment, so delta of the landed column should be +1 .\n",
    "#\n",
    "from pyspark.sql.functions import col, lag\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "\n",
    "w = Window.partitionBy(\"flight\").orderBy(\"time\")\n",
    "\n",
    "diff = col(\"landed\").cast(\"int\") - lag(\"landed\", 1).over(w).cast(\"int\")\n",
    "tracks_touchdown_df = tracks_df.select([\"flight\",\"time\",\"lat\",\"lon\",\"heading\",\"landed\",\"registration\"]).withColumn(\"touchdown\", diff)\n",
    "tracks_touchdown_df = tracks_touchdown_df.withColumn(\"runway\", \\\n",
    "                            udf_func2(tracks_touchdown_df.lon,tracks_touchdown_df.lat,tracks_touchdown_df.heading))\n",
    "tracks_touchdown_df = tracks_touchdown_df.where(\"touchdown == 1\").select(col(\"flight\").alias(\"flight_touchdown\"), \\\n",
    "                                                                         col(\"runway\").alias(\"runway_touchdown\"), \\\n",
    "                                                                         col(\"time\").alias(\"time_touchdown\") )\n",
    "tracks_touchdown_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+\n",
      "|flight_touchdown|count|\n",
      "+----------------+-----+\n",
      "|          HV6118|    2|\n",
      "|          HV5134|    2|\n",
      "|          KL1412|    2|\n",
      "|          HV6332|    2|\n",
      "|          HV5356|   19|\n",
      "|          HV5314|    2|\n",
      "|           TP668|    2|\n",
      "|          HV6146|    2|\n",
      "+----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check for multiple landings 1 flight\n",
    "#tracks_touchdown_df.groupby([\"flight\",\"registration\"]).count().where(\"count > 1\").show()\n",
    "tracks_touchdown_df.groupby([\"flight_touchdown\"]).count().where(\"count > 1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#remove them\n",
    "tracks_touchdown_df = tracks_touchdown_df.where(\"flight_touchdown != 'HV6118' and flight_touchdown != 'HV5134' and flight_touchdown != 'KL1412' and flight_touchdown != 'HV6332' and flight_touchdown != 'HV5356' and flight_touchdown != 'HV5314' and flight_touchdown != 'TP668' and flight_touchdown != 'HV6146' \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+\n",
      "|flight_touchdown|count|\n",
      "+----------------+-----+\n",
      "+----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check again\n",
    "tracks_touchdown_df.groupby([\"flight_touchdown\"]).count().where(\"count > 1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#join tracks with our landing table and add column showing time till land\n",
    "join_df = tracks_df.join(tracks_touchdown_df,tracks_df.flight == tracks_touchdown_df.flight_touchdown)\n",
    "join_df = join_df.withColumn(\"time_till_landing\",col(\"time_touchdown\") - col(\"time\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#get rid of > 7000 sec , so we make sure flights on the next day are not using the landing of current day\n",
    "join_df = join_df.where(\"time_till_landing > -7000\")\n",
    "\n",
    "#ML require positive, but we dont want to remove that, we want to calc in block time later on\n",
    "join_df = join_df.withColumn(\"time_till_landing\", udf_func3(join_df.time_till_landing))  \n",
    "join_df = join_df.withColumn(\"time_till_landing_minutes\",join_df.time_till_landing / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>na</th>\n",
       "      <th>altitude</th>\n",
       "      <th>dest</th>\n",
       "      <th>heading</th>\n",
       "      <th>flight</th>\n",
       "      <th>fltid</th>\n",
       "      <th>landed</th>\n",
       "      <th>time</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>...</th>\n",
       "      <th>altitude_delta</th>\n",
       "      <th>distance_to_ams</th>\n",
       "      <th>flight_touchdown</th>\n",
       "      <th>runway_touchdown</th>\n",
       "      <th>time_touchdown</th>\n",
       "      <th>time_till_landing</th>\n",
       "      <th>time_till_landing_minutes</th>\n",
       "      <th>flight_maxtime</th>\n",
       "      <th>time_onblock</th>\n",
       "      <th>time_till_onblock_minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>38000</td>\n",
       "      <td>AMS</td>\n",
       "      <td>322</td>\n",
       "      <td>CND518</td>\n",
       "      <td>a20c9e8</td>\n",
       "      <td>0</td>\n",
       "      <td>1466786890</td>\n",
       "      <td>45.443802</td>\n",
       "      <td>16.942801</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1169.708008</td>\n",
       "      <td>CND518</td>\n",
       "      <td>8</td>\n",
       "      <td>1466792627</td>\n",
       "      <td>5737</td>\n",
       "      <td>95.616667</td>\n",
       "      <td>CND518</td>\n",
       "      <td>1466792943</td>\n",
       "      <td>100.883333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>38000</td>\n",
       "      <td>AMS</td>\n",
       "      <td>309</td>\n",
       "      <td>CND518</td>\n",
       "      <td>a20c9e8</td>\n",
       "      <td>0</td>\n",
       "      <td>1466788240</td>\n",
       "      <td>47.907600</td>\n",
       "      <td>14.943300</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>873.840332</td>\n",
       "      <td>CND518</td>\n",
       "      <td>8</td>\n",
       "      <td>1466792627</td>\n",
       "      <td>4387</td>\n",
       "      <td>73.116667</td>\n",
       "      <td>CND518</td>\n",
       "      <td>1466792943</td>\n",
       "      <td>78.383333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AMS</td>\n",
       "      <td>326</td>\n",
       "      <td>CND518</td>\n",
       "      <td>a20c9e8</td>\n",
       "      <td>1</td>\n",
       "      <td>1466792817</td>\n",
       "      <td>52.313702</td>\n",
       "      <td>4.759000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.560867</td>\n",
       "      <td>CND518</td>\n",
       "      <td>8</td>\n",
       "      <td>1466792627</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>CND518</td>\n",
       "      <td>1466792943</td>\n",
       "      <td>2.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>38000</td>\n",
       "      <td>AMS</td>\n",
       "      <td>322</td>\n",
       "      <td>CND518</td>\n",
       "      <td>a20c9e8</td>\n",
       "      <td>0</td>\n",
       "      <td>1466786574</td>\n",
       "      <td>44.901600</td>\n",
       "      <td>17.529200</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1244.882324</td>\n",
       "      <td>CND518</td>\n",
       "      <td>8</td>\n",
       "      <td>1466792627</td>\n",
       "      <td>6053</td>\n",
       "      <td>100.883333</td>\n",
       "      <td>CND518</td>\n",
       "      <td>1466792943</td>\n",
       "      <td>106.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>10850</td>\n",
       "      <td>AMS</td>\n",
       "      <td>343</td>\n",
       "      <td>CND518</td>\n",
       "      <td>a20c9e8</td>\n",
       "      <td>0</td>\n",
       "      <td>1466784462</td>\n",
       "      <td>41.194099</td>\n",
       "      <td>20.736401</td>\n",
       "      <td>...</td>\n",
       "      <td>1152</td>\n",
       "      <td>1726.118042</td>\n",
       "      <td>CND518</td>\n",
       "      <td>8</td>\n",
       "      <td>1466792627</td>\n",
       "      <td>8165</td>\n",
       "      <td>136.083333</td>\n",
       "      <td>CND518</td>\n",
       "      <td>1466792943</td>\n",
       "      <td>141.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>38000</td>\n",
       "      <td>AMS</td>\n",
       "      <td>309</td>\n",
       "      <td>CND518</td>\n",
       "      <td>a20c9e8</td>\n",
       "      <td>0</td>\n",
       "      <td>1466788298</td>\n",
       "      <td>47.987598</td>\n",
       "      <td>14.800400</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>859.987732</td>\n",
       "      <td>CND518</td>\n",
       "      <td>8</td>\n",
       "      <td>1466792627</td>\n",
       "      <td>4329</td>\n",
       "      <td>72.150000</td>\n",
       "      <td>CND518</td>\n",
       "      <td>1466792943</td>\n",
       "      <td>77.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>36000</td>\n",
       "      <td>AMS</td>\n",
       "      <td>311</td>\n",
       "      <td>CND518</td>\n",
       "      <td>a20c9e8</td>\n",
       "      <td>0</td>\n",
       "      <td>1466790974</td>\n",
       "      <td>51.670502</td>\n",
       "      <td>7.977600</td>\n",
       "      <td>...</td>\n",
       "      <td>64</td>\n",
       "      <td>231.215576</td>\n",
       "      <td>CND518</td>\n",
       "      <td>8</td>\n",
       "      <td>1466792627</td>\n",
       "      <td>1653</td>\n",
       "      <td>27.550000</td>\n",
       "      <td>CND518</td>\n",
       "      <td>1466792943</td>\n",
       "      <td>32.816667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>38000</td>\n",
       "      <td>AMS</td>\n",
       "      <td>309</td>\n",
       "      <td>CND518</td>\n",
       "      <td>a20c9e8</td>\n",
       "      <td>0</td>\n",
       "      <td>1466789568</td>\n",
       "      <td>49.727402</td>\n",
       "      <td>11.632400</td>\n",
       "      <td>...</td>\n",
       "      <td>-64</td>\n",
       "      <td>559.123230</td>\n",
       "      <td>CND518</td>\n",
       "      <td>8</td>\n",
       "      <td>1466792627</td>\n",
       "      <td>3059</td>\n",
       "      <td>50.983333</td>\n",
       "      <td>CND518</td>\n",
       "      <td>1466792943</td>\n",
       "      <td>56.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>38000</td>\n",
       "      <td>AMS</td>\n",
       "      <td>308</td>\n",
       "      <td>CND518</td>\n",
       "      <td>a20c9e8</td>\n",
       "      <td>0</td>\n",
       "      <td>1466789758</td>\n",
       "      <td>49.982498</td>\n",
       "      <td>11.143100</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>514.278992</td>\n",
       "      <td>CND518</td>\n",
       "      <td>8</td>\n",
       "      <td>1466792627</td>\n",
       "      <td>2869</td>\n",
       "      <td>47.816667</td>\n",
       "      <td>CND518</td>\n",
       "      <td>1466792943</td>\n",
       "      <td>53.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>38000</td>\n",
       "      <td>AMS</td>\n",
       "      <td>327</td>\n",
       "      <td>CND518</td>\n",
       "      <td>a20c9e8</td>\n",
       "      <td>0</td>\n",
       "      <td>1466785879</td>\n",
       "      <td>43.567200</td>\n",
       "      <td>18.542200</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1408.481812</td>\n",
       "      <td>CND518</td>\n",
       "      <td>8</td>\n",
       "      <td>1466792627</td>\n",
       "      <td>6748</td>\n",
       "      <td>112.466667</td>\n",
       "      <td>CND518</td>\n",
       "      <td>1466792943</td>\n",
       "      <td>117.733333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  na  altitude dest  heading  flight    fltid  landed        time        lat  \\\n",
       "0  0     38000  AMS      322  CND518  a20c9e8       0  1466786890  45.443802   \n",
       "1  0     38000  AMS      309  CND518  a20c9e8       0  1466788240  47.907600   \n",
       "2  0         0  AMS      326  CND518  a20c9e8       1  1466792817  52.313702   \n",
       "3  0     38000  AMS      322  CND518  a20c9e8       0  1466786574  44.901600   \n",
       "4  0     10850  AMS      343  CND518  a20c9e8       0  1466784462  41.194099   \n",
       "5  0     38000  AMS      309  CND518  a20c9e8       0  1466788298  47.987598   \n",
       "6  0     36000  AMS      311  CND518  a20c9e8       0  1466790974  51.670502   \n",
       "7  0     38000  AMS      309  CND518  a20c9e8       0  1466789568  49.727402   \n",
       "8  0     38000  AMS      308  CND518  a20c9e8       0  1466789758  49.982498   \n",
       "9  0     38000  AMS      327  CND518  a20c9e8       0  1466785879  43.567200   \n",
       "\n",
       "         lon            ...             altitude_delta distance_to_ams  \\\n",
       "0  16.942801            ...                          0     1169.708008   \n",
       "1  14.943300            ...                          0      873.840332   \n",
       "2   4.759000            ...                          0        0.560867   \n",
       "3  17.529200            ...                          0     1244.882324   \n",
       "4  20.736401            ...                       1152     1726.118042   \n",
       "5  14.800400            ...                          0      859.987732   \n",
       "6   7.977600            ...                         64      231.215576   \n",
       "7  11.632400            ...                        -64      559.123230   \n",
       "8  11.143100            ...                          0      514.278992   \n",
       "9  18.542200            ...                          0     1408.481812   \n",
       "\n",
       "  flight_touchdown runway_touchdown time_touchdown  time_till_landing  \\\n",
       "0           CND518                8     1466792627               5737   \n",
       "1           CND518                8     1466792627               4387   \n",
       "2           CND518                8     1466792627                  0   \n",
       "3           CND518                8     1466792627               6053   \n",
       "4           CND518                8     1466792627               8165   \n",
       "5           CND518                8     1466792627               4329   \n",
       "6           CND518                8     1466792627               1653   \n",
       "7           CND518                8     1466792627               3059   \n",
       "8           CND518                8     1466792627               2869   \n",
       "9           CND518                8     1466792627               6748   \n",
       "\n",
       "  time_till_landing_minutes flight_maxtime  time_onblock  \\\n",
       "0                 95.616667         CND518    1466792943   \n",
       "1                 73.116667         CND518    1466792943   \n",
       "2                  0.000000         CND518    1466792943   \n",
       "3                100.883333         CND518    1466792943   \n",
       "4                136.083333         CND518    1466792943   \n",
       "5                 72.150000         CND518    1466792943   \n",
       "6                 27.550000         CND518    1466792943   \n",
       "7                 50.983333         CND518    1466792943   \n",
       "8                 47.816667         CND518    1466792943   \n",
       "9                112.466667         CND518    1466792943   \n",
       "\n",
       "   time_till_onblock_minutes  \n",
       "0                 100.883333  \n",
       "1                  78.383333  \n",
       "2                   2.100000  \n",
       "3                 106.150000  \n",
       "4                 141.350000  \n",
       "5                  77.416667  \n",
       "6                  32.816667  \n",
       "7                  56.250000  \n",
       "8                  53.083333  \n",
       "9                 117.733333  \n",
       "\n",
       "[10 rows x 28 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import max,min\n",
    "\n",
    "#LEts us join_df to add the pier used to park, so we calculate on block\n",
    "maxtime_df = join_df.groupby(col(\"flight\").alias(\"flight_maxtime\")).agg(max(\"time\").alias(\"time_onblock\"))\n",
    "join_maxtime_df = join_df.join(maxtime_df,join_df.flight == maxtime_df.flight_maxtime)\n",
    "join_maxtime_df = join_maxtime_df.withColumn(\"time_till_onblock_minutes\",(col(\"time_onblock\") - col(\"time\")) / 60)\n",
    "\n",
    "join_maxtime_df.toPandas().head(10) #show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "join_df = join_maxtime_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tracks_df.select(\"flight\").distinct().count() #747 planes, might be all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = join_df.toPandas().query(\"flight == 'KL214'\").sort_values(['time']).reset_index()\n",
    "join_df.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Machine learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_till_onblock_minutes</th>\n",
       "      <th>distance_to_ams</th>\n",
       "      <th>speed</th>\n",
       "      <th>altitude</th>\n",
       "      <th>heading</th>\n",
       "      <th>runway_touchdown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.883333</td>\n",
       "      <td>1169.708008</td>\n",
       "      <td>465</td>\n",
       "      <td>38000</td>\n",
       "      <td>322</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78.383333</td>\n",
       "      <td>873.840332</td>\n",
       "      <td>456</td>\n",
       "      <td>38000</td>\n",
       "      <td>309</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.100000</td>\n",
       "      <td>0.560867</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>326</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.150000</td>\n",
       "      <td>1244.882324</td>\n",
       "      <td>476</td>\n",
       "      <td>38000</td>\n",
       "      <td>322</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>141.350000</td>\n",
       "      <td>1726.118042</td>\n",
       "      <td>314</td>\n",
       "      <td>10850</td>\n",
       "      <td>343</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>77.416667</td>\n",
       "      <td>859.987732</td>\n",
       "      <td>456</td>\n",
       "      <td>38000</td>\n",
       "      <td>309</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>32.816667</td>\n",
       "      <td>231.215576</td>\n",
       "      <td>473</td>\n",
       "      <td>36000</td>\n",
       "      <td>311</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>56.250000</td>\n",
       "      <td>559.123230</td>\n",
       "      <td>464</td>\n",
       "      <td>38000</td>\n",
       "      <td>309</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>53.083333</td>\n",
       "      <td>514.278992</td>\n",
       "      <td>459</td>\n",
       "      <td>38000</td>\n",
       "      <td>308</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>117.733333</td>\n",
       "      <td>1408.481812</td>\n",
       "      <td>479</td>\n",
       "      <td>38000</td>\n",
       "      <td>327</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>88.000000</td>\n",
       "      <td>996.119568</td>\n",
       "      <td>449</td>\n",
       "      <td>38000</td>\n",
       "      <td>335</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>116.716667</td>\n",
       "      <td>1393.996826</td>\n",
       "      <td>477</td>\n",
       "      <td>38000</td>\n",
       "      <td>327</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>91.266667</td>\n",
       "      <td>1037.474609</td>\n",
       "      <td>453</td>\n",
       "      <td>38000</td>\n",
       "      <td>335</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>18.083333</td>\n",
       "      <td>56.418419</td>\n",
       "      <td>320</td>\n",
       "      <td>7725</td>\n",
       "      <td>276</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>41.216667</td>\n",
       "      <td>347.197021</td>\n",
       "      <td>469</td>\n",
       "      <td>38000</td>\n",
       "      <td>312</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>135.150000</td>\n",
       "      <td>1658.515015</td>\n",
       "      <td>420</td>\n",
       "      <td>24000</td>\n",
       "      <td>302</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>72.116667</td>\n",
       "      <td>785.348999</td>\n",
       "      <td>461</td>\n",
       "      <td>38000</td>\n",
       "      <td>309</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>29.650000</td>\n",
       "      <td>189.109848</td>\n",
       "      <td>486</td>\n",
       "      <td>33350</td>\n",
       "      <td>311</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>57.350000</td>\n",
       "      <td>574.542786</td>\n",
       "      <td>463</td>\n",
       "      <td>38000</td>\n",
       "      <td>309</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9.516667</td>\n",
       "      <td>16.019865</td>\n",
       "      <td>177</td>\n",
       "      <td>2200</td>\n",
       "      <td>183</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>86.850000</td>\n",
       "      <td>981.617554</td>\n",
       "      <td>450</td>\n",
       "      <td>38000</td>\n",
       "      <td>336</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>66.850000</td>\n",
       "      <td>710.443298</td>\n",
       "      <td>468</td>\n",
       "      <td>38000</td>\n",
       "      <td>310</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>131.583333</td>\n",
       "      <td>1611.395508</td>\n",
       "      <td>469</td>\n",
       "      <td>28750</td>\n",
       "      <td>327</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>99.800000</td>\n",
       "      <td>1153.938965</td>\n",
       "      <td>466</td>\n",
       "      <td>38000</td>\n",
       "      <td>322</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>84.750000</td>\n",
       "      <td>955.229919</td>\n",
       "      <td>451</td>\n",
       "      <td>38000</td>\n",
       "      <td>336</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>30.716667</td>\n",
       "      <td>203.243423</td>\n",
       "      <td>483</td>\n",
       "      <td>34375</td>\n",
       "      <td>311</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>21.250000</td>\n",
       "      <td>86.925240</td>\n",
       "      <td>384</td>\n",
       "      <td>14275</td>\n",
       "      <td>290</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>103.000000</td>\n",
       "      <td>1199.453613</td>\n",
       "      <td>465</td>\n",
       "      <td>38000</td>\n",
       "      <td>322</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>27.550000</td>\n",
       "      <td>162.852463</td>\n",
       "      <td>455</td>\n",
       "      <td>29350</td>\n",
       "      <td>311</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>111.466667</td>\n",
       "      <td>1320.907471</td>\n",
       "      <td>477</td>\n",
       "      <td>38000</td>\n",
       "      <td>336</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91159</th>\n",
       "      <td>2.616667</td>\n",
       "      <td>1.161670</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91160</th>\n",
       "      <td>70.450000</td>\n",
       "      <td>665.882507</td>\n",
       "      <td>237</td>\n",
       "      <td>3850</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91161</th>\n",
       "      <td>62.650000</td>\n",
       "      <td>591.340088</td>\n",
       "      <td>420</td>\n",
       "      <td>20550</td>\n",
       "      <td>334</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91162</th>\n",
       "      <td>39.450000</td>\n",
       "      <td>274.831238</td>\n",
       "      <td>481</td>\n",
       "      <td>38000</td>\n",
       "      <td>312</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91163</th>\n",
       "      <td>26.650000</td>\n",
       "      <td>135.818924</td>\n",
       "      <td>341</td>\n",
       "      <td>23100</td>\n",
       "      <td>280</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91164</th>\n",
       "      <td>16.916667</td>\n",
       "      <td>53.532955</td>\n",
       "      <td>274</td>\n",
       "      <td>8725</td>\n",
       "      <td>279</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91165</th>\n",
       "      <td>35.183333</td>\n",
       "      <td>220.382309</td>\n",
       "      <td>479</td>\n",
       "      <td>35725</td>\n",
       "      <td>321</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91166</th>\n",
       "      <td>50.016667</td>\n",
       "      <td>424.241364</td>\n",
       "      <td>480</td>\n",
       "      <td>35425</td>\n",
       "      <td>324</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91167</th>\n",
       "      <td>5.466667</td>\n",
       "      <td>1.551501</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91168</th>\n",
       "      <td>2.616667</td>\n",
       "      <td>1.161670</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91169</th>\n",
       "      <td>53.133333</td>\n",
       "      <td>467.207092</td>\n",
       "      <td>485</td>\n",
       "      <td>34000</td>\n",
       "      <td>325</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91170</th>\n",
       "      <td>3.366667</td>\n",
       "      <td>1.308269</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91171</th>\n",
       "      <td>59.433333</td>\n",
       "      <td>552.495789</td>\n",
       "      <td>461</td>\n",
       "      <td>26550</td>\n",
       "      <td>339</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91172</th>\n",
       "      <td>44.716667</td>\n",
       "      <td>348.965057</td>\n",
       "      <td>475</td>\n",
       "      <td>38000</td>\n",
       "      <td>309</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91173</th>\n",
       "      <td>41.550000</td>\n",
       "      <td>304.384583</td>\n",
       "      <td>476</td>\n",
       "      <td>38000</td>\n",
       "      <td>313</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91174</th>\n",
       "      <td>37.350000</td>\n",
       "      <td>246.923889</td>\n",
       "      <td>474</td>\n",
       "      <td>38000</td>\n",
       "      <td>320</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91175</th>\n",
       "      <td>12.850000</td>\n",
       "      <td>31.406094</td>\n",
       "      <td>229</td>\n",
       "      <td>4625</td>\n",
       "      <td>266</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91176</th>\n",
       "      <td>40.550000</td>\n",
       "      <td>290.224854</td>\n",
       "      <td>478</td>\n",
       "      <td>38000</td>\n",
       "      <td>313</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91177</th>\n",
       "      <td>74.616667</td>\n",
       "      <td>662.409607</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>351</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91178</th>\n",
       "      <td>65.950000</td>\n",
       "      <td>627.713257</td>\n",
       "      <td>357</td>\n",
       "      <td>12725</td>\n",
       "      <td>334</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91179</th>\n",
       "      <td>9.683333</td>\n",
       "      <td>20.077810</td>\n",
       "      <td>180</td>\n",
       "      <td>2975</td>\n",
       "      <td>185</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91180</th>\n",
       "      <td>68.200000</td>\n",
       "      <td>647.676147</td>\n",
       "      <td>280</td>\n",
       "      <td>7475</td>\n",
       "      <td>335</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91181</th>\n",
       "      <td>60.483333</td>\n",
       "      <td>565.199646</td>\n",
       "      <td>445</td>\n",
       "      <td>24900</td>\n",
       "      <td>339</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91182</th>\n",
       "      <td>73.516667</td>\n",
       "      <td>662.409607</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91183</th>\n",
       "      <td>11.766667</td>\n",
       "      <td>28.498869</td>\n",
       "      <td>188</td>\n",
       "      <td>4100</td>\n",
       "      <td>264</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91184</th>\n",
       "      <td>57.316667</td>\n",
       "      <td>524.793579</td>\n",
       "      <td>468</td>\n",
       "      <td>29750</td>\n",
       "      <td>325</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91185</th>\n",
       "      <td>14.866667</td>\n",
       "      <td>40.645931</td>\n",
       "      <td>263</td>\n",
       "      <td>6450</td>\n",
       "      <td>271</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91186</th>\n",
       "      <td>29.850000</td>\n",
       "      <td>170.338760</td>\n",
       "      <td>370</td>\n",
       "      <td>26000</td>\n",
       "      <td>281</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91187</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.685573</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>340</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91188</th>\n",
       "      <td>18.983333</td>\n",
       "      <td>66.344124</td>\n",
       "      <td>291</td>\n",
       "      <td>11150</td>\n",
       "      <td>291</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91189 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       time_till_onblock_minutes  distance_to_ams  speed  altitude  heading  \\\n",
       "0                     100.883333      1169.708008    465     38000      322   \n",
       "1                      78.383333       873.840332    456     38000      309   \n",
       "2                       2.100000         0.560867      0         0      326   \n",
       "3                     106.150000      1244.882324    476     38000      322   \n",
       "4                     141.350000      1726.118042    314     10850      343   \n",
       "5                      77.416667       859.987732    456     38000      309   \n",
       "6                      32.816667       231.215576    473     36000      311   \n",
       "7                      56.250000       559.123230    464     38000      309   \n",
       "8                      53.083333       514.278992    459     38000      308   \n",
       "9                     117.733333      1408.481812    479     38000      327   \n",
       "10                     88.000000       996.119568    449     38000      335   \n",
       "11                    116.716667      1393.996826    477     38000      327   \n",
       "12                     91.266667      1037.474609    453     38000      335   \n",
       "13                     18.083333        56.418419    320      7725      276   \n",
       "14                     41.216667       347.197021    469     38000      312   \n",
       "15                    135.150000      1658.515015    420     24000      302   \n",
       "16                     72.116667       785.348999    461     38000      309   \n",
       "17                     29.650000       189.109848    486     33350      311   \n",
       "18                     57.350000       574.542786    463     38000      309   \n",
       "19                      9.516667        16.019865    177      2200      183   \n",
       "20                     86.850000       981.617554    450     38000      336   \n",
       "21                     66.850000       710.443298    468     38000      310   \n",
       "22                    131.583333      1611.395508    469     28750      327   \n",
       "23                     99.800000      1153.938965    466     38000      322   \n",
       "24                     84.750000       955.229919    451     38000      336   \n",
       "25                     30.716667       203.243423    483     34375      311   \n",
       "26                     21.250000        86.925240    384     14275      290   \n",
       "27                    103.000000      1199.453613    465     38000      322   \n",
       "28                     27.550000       162.852463    455     29350      311   \n",
       "29                    111.466667      1320.907471    477     38000      336   \n",
       "...                          ...              ...    ...       ...      ...   \n",
       "91159                   2.616667         1.161670     19         0       56   \n",
       "91160                  70.450000       665.882507    237      3850        6   \n",
       "91161                  62.650000       591.340088    420     20550      334   \n",
       "91162                  39.450000       274.831238    481     38000      312   \n",
       "91163                  26.650000       135.818924    341     23100      280   \n",
       "91164                  16.916667        53.532955    274      8725      279   \n",
       "91165                  35.183333       220.382309    479     35725      321   \n",
       "91166                  50.016667       424.241364    480     35425      324   \n",
       "91167                   5.466667         1.551501     25         0      154   \n",
       "91168                   2.616667         1.161670     19         0       56   \n",
       "91169                  53.133333       467.207092    485     34000      325   \n",
       "91170                   3.366667         1.308269     24         0      132   \n",
       "91171                  59.433333       552.495789    461     26550      339   \n",
       "91172                  44.716667       348.965057    475     38000      309   \n",
       "91173                  41.550000       304.384583    476     38000      313   \n",
       "91174                  37.350000       246.923889    474     38000      320   \n",
       "91175                  12.850000        31.406094    229      4625      266   \n",
       "91176                  40.550000       290.224854    478     38000      313   \n",
       "91177                  74.616667       662.409607      2         0      351   \n",
       "91178                  65.950000       627.713257    357     12725      334   \n",
       "91179                   9.683333        20.077810    180      2975      185   \n",
       "91180                  68.200000       647.676147    280      7475      335   \n",
       "91181                  60.483333       565.199646    445     24900      339   \n",
       "91182                  73.516667       662.409607      0         0       56   \n",
       "91183                  11.766667        28.498869    188      4100      264   \n",
       "91184                  57.316667       524.793579    468     29750      325   \n",
       "91185                  14.866667        40.645931    263      6450      271   \n",
       "91186                  29.850000       170.338760    370     26000      281   \n",
       "91187                   0.500000         0.685573     15         0      340   \n",
       "91188                  18.983333        66.344124    291     11150      291   \n",
       "\n",
       "       runway_touchdown  \n",
       "0                     8  \n",
       "1                     8  \n",
       "2                     8  \n",
       "3                     8  \n",
       "4                     8  \n",
       "5                     8  \n",
       "6                     8  \n",
       "7                     8  \n",
       "8                     8  \n",
       "9                     8  \n",
       "10                    8  \n",
       "11                    8  \n",
       "12                    8  \n",
       "13                    8  \n",
       "14                    8  \n",
       "15                    8  \n",
       "16                    8  \n",
       "17                    8  \n",
       "18                    8  \n",
       "19                    8  \n",
       "20                    8  \n",
       "21                    8  \n",
       "22                    8  \n",
       "23                    8  \n",
       "24                    8  \n",
       "25                    8  \n",
       "26                    8  \n",
       "27                    8  \n",
       "28                    8  \n",
       "29                    8  \n",
       "...                 ...  \n",
       "91159                 2  \n",
       "91160                 2  \n",
       "91161                 2  \n",
       "91162                 2  \n",
       "91163                 2  \n",
       "91164                 2  \n",
       "91165                 2  \n",
       "91166                 2  \n",
       "91167                 2  \n",
       "91168                 2  \n",
       "91169                 2  \n",
       "91170                 2  \n",
       "91171                 2  \n",
       "91172                 2  \n",
       "91173                 2  \n",
       "91174                 2  \n",
       "91175                 2  \n",
       "91176                 2  \n",
       "91177                 2  \n",
       "91178                 2  \n",
       "91179                 2  \n",
       "91180                 2  \n",
       "91181                 2  \n",
       "91182                 2  \n",
       "91183                 2  \n",
       "91184                 2  \n",
       "91185                 2  \n",
       "91186                 2  \n",
       "91187                 2  \n",
       "91188                 2  \n",
       "\n",
       "[91189 rows x 6 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Create our machine learing dataset\n",
    "ml_df = join_df.select(['time_till_onblock_minutes','distance_to_ams','speed','altitude','heading','runway_touchdown'])\n",
    "#ml_df = ml_df.withColumn('id',fn.monotonically_increasing_id())\n",
    "ml_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data, testing_data = ml_df.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ml_df.toPandas().to_csv('/root/fr24/fr24.csv', sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "#Change label to time_till_landing_minutes if you want to predict that field\n",
    "assembler = VectorAssembler(inputCols=[\"distance_to_ams\",\"speed\",\"altitude\",\"heading\",\"runway_touchdown\"],outputCol=\"features\")\n",
    "Regressor = DecisionTreeRegressor(featuresCol=\"features\",labelCol=\"time_till_onblock_minutes\",maxDepth=25)\n",
    "pipeline = Pipeline(stages=[assembler,Regressor])\n",
    "model = pipeline.fit(training_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = model.transform(testing_data)\n",
    "modelEvaluator = RegressionEvaluator(labelCol=\"time_till_onblock_minutes\")\n",
    "modelError = modelEvaluator.evaluate(predictions) #rmse by default\n",
    "modelError = modelEvaluator.evaluate(predictions,{modelEvaluator.metricName: \"mae\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.527337220404774"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelError #time landing 4,5 minutes, 6,5 minutes for onblock time. Will try to improve using pier for parking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions.toPandas().head(100) #show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lets try random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[\"distance_to_ams\",\"speed\",\"altitude\",\"heading\",\"runway\"],outputCol=\"features\")\n",
    "Regressor = RandomForestRegressor(featuresCol=\"features\",labelCol=\"time_till_landing_minutes\",maxDepth=5)\n",
    "\n",
    "#pipeline = Pipeline(stages=[isLondonIndexer,durationIndexer,typeIndexer,assembler,Regressor])\n",
    "pipeline = Pipeline(stages=[assembler,Regressor])\n",
    "model = pipeline.fit(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test again with new model\n",
    "predictions = model.transform(testing_data)\n",
    "modelEvaluator = RegressionEvaluator(labelCol=\"time_till_landing_minutes\")\n",
    "modelError = modelEvaluator.evaluate(predictions) #rmse by default\n",
    "modelError = modelEvaluator.evaluate(predictions,{modelEvaluator.metricName: \"mae\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#22 mins with default settings depth 5, 9 mins with depth 10.\n",
    "#6,4 with depth 15. Crashed with 20 depth on mac\n",
    "modelError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Grid-search first , later train validation\n",
    "grid = tune.ParamGridBuilder() \\\n",
    "       .addGrid(logistic.maxIter,\n",
    "                [2, 10, 50]) \\\n",
    "       .addGrid(logistic.regParam,\n",
    "                [0.01, 0.05, 0.3]) \\\n",
    "       .build()\n",
    "    \n",
    "evaluator = ev.BinaryClassificationEvaluator( \\\n",
    "       rawPredictionCol='probability', \\\n",
    "       labelCol='INFANT_ALIVE_AT_REPORT')\n",
    "    \n",
    "cv = tune.CrossValidator( \\\n",
    "       estimator=logistic, \\\n",
    "       estimatorParamMaps=grid, \\\n",
    "       evaluator=evaluator\n",
    ")\n",
    "    \n",
    "pipeline = Pipeline(stages=[encoder ,featuresCreator])\n",
    "data_transformer = pipeline.fit(births_train)\n",
    "cvModel = cv.fit(data_transformer.transform(births_train))\n",
    "\n",
    "data_train = data_transformer \\\n",
    "       .transform(births_test)\n",
    "results = cvModel.transform(data_train)\n",
    "print(evaluator.evaluate(results, \\\n",
    "        {evaluator.metricName: 'areaUnderROC'}))\n",
    "print(evaluator.evaluate(results, \\\n",
    "        {evaluator.metricName: 'areaUnderPR'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification example\n",
    "\n",
    "```\n",
    "import pyspark.ml.classification as cl\n",
    "from pyspark.ml import Pipeline\n",
    "import pyspark.ml.evaluation as ev\n",
    "\n",
    "encoder = ft.OneHotEncoder(\n",
    "       inputCol='BIRTH_PLACE_INT',\n",
    "       outputCol='BIRTH_PLACE_VEC')\n",
    "       \n",
    "\n",
    "logistic = cl.LogisticRegression(\n",
    "       maxIter=10,\n",
    "       regParam=0.01,\n",
    "       labelCol='some_classifation')\n",
    "\n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "           encoder,\n",
    "           featuresCreator,logistic ])\n",
    "    \n",
    "births_train, births_test = births \\\n",
    "       .randomSplit([0.7, 0.3], seed=666)\n",
    "    \n",
    "model = pipeline.fit(births_train)\n",
    "test_model = model.transform(births_test)  \n",
    "\n",
    "valuator = ev.BinaryClassificationEvaluator(\n",
    "       rawPredictionCol='probability',\n",
    "       labelCol='INFANT_ALIVE_AT_REPORT')\n",
    "       \n",
    "pipelinePath = './infant_oneHotEncoder_Logistic_Pipeline'\n",
    "pipeline.write().overwrite().save(pipelinePath)\n",
    "\n",
    "to load:\n",
    "loadedPipeline = Pipeline.load(pipelinePath)\n",
    "loadedPipeline \\\n",
    "       .fit(births_train)\\\n",
    "       .transform(births_test)\\\n",
    "       .take(1)\n",
    "       \n",
    "       \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "What would happen if we have a string based column?\n",
    "\n",
    "Make it a number\n",
    "births = births \\\n",
    "       .withColumn('BIRTH_PLACE_INT', births['BIRTH_PLACE'] \\\n",
    "       .cast(typ.IntegerType()))\n",
    "       \n",
    "       \n",
    "   encoder = ft.OneHotEncoder(\n",
    "       inputCol='BIRTH_PLACE_INT',\n",
    "       outputCol='BIRTH_PLACE_VEC')\n",
    "       \n",
    "Like before create the assembler, but we use getoutputcol so we \n",
    "dont care about the real column name:\n",
    "   featuresCreator = ft.VectorAssembler(\n",
    "       inputCols=[\n",
    "           col[0]\n",
    "           for col\n",
    "           in labels[2:]] + \\\n",
    "       [encoder.getOutputCol()],\n",
    "     outputCol='features'\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import bokeh.charts as chrt\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ml_df.where(\"time_till_landing_minutes < 0\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "hists = ml_df.select('time_till_landing_minutes').rdd.flatMap(\n",
    "       lambda row: row\n",
    ").histogram(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_hist = {\n",
    "       'bins': hists[0][:-1],\n",
    "       'freq': hists[1]\n",
    "   }\n",
    "plt.bar(data_hist['bins'], data_hist['freq'], width=20)\n",
    "plt.title('Histogram of \\'time_till_landing\\'')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "b_hist = chrt.Bar(\n",
    "       data_hist,\n",
    "       values='freq', label='bins',\n",
    "       title='Histogram of \\'balance\\'')\n",
    "chrt.show(b_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "percent_back = 0.001\n",
    "\n",
    "# use this if you want an (almost) exact number of samples\n",
    "# sample_count = 200\n",
    "# percent_back = sample_count / posts.count()\n",
    "\n",
    "frac = dict(\n",
    "    (e.time_till_landing_minutes, percent_back) \n",
    "    for e \n",
    "    in ml_df.select('time_till_landing_minutes').distinct().collect()\n",
    ")\n",
    "sampled = ml_df.sampleBy('time_till_landing_minutes', fractions=frac)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sampled.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark",
   "language": "python",
   "name": "spark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
